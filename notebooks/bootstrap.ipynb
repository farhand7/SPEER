{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "import logistic_regression as lr\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = pd.read_csv('../input/g_train.csv', index_col=(0,1))\n",
    "e = pd.read_csv('../input/expression.short.csv', index_col=(0,1))\n",
    "train = pd.concat([g,e[\"median\"]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n1 = pd.read_csv(\"../src_output/9.13.16.tissuesphysiologicalgroups4/n1.csv\", index_col=(0,1))\n",
    "n2 = pd.read_csv(\"../src_output/9.13.16.tissuesphysiologicalgroups4/n2.csv\", index_col=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add discrete training labels\n",
    "train[\"labels\"] = sklearn.preprocessing.binarize(np.abs(train[\"median\"].values).reshape(-1,1), threshold = 1.5).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### processing data helper functions #####\n",
    "def processTissueGroups(tissue_groups_path):\n",
    "    tissue_groups = {}\n",
    "    f = open(tissue_groups_path)\n",
    "    for l in f:\n",
    "        w = l.strip().split(',')\n",
    "        group = w[0]\n",
    "        tissue_groups[group] = []\n",
    "        for tissue in w[1:]: tissue_groups[group].append(tissue)\n",
    "    return tissue_groups    \n",
    "    \n",
    "\n",
    "def generateTrainTest(train, annotation_columns):\n",
    "    '''\n",
    "        Training data contains annotation columns and other data columns\n",
    "        annotation_columns is a list of genomic annotations\n",
    "    '''\n",
    "    annotation_columns.insert(0, 'gene_id')\n",
    "    train.insert(0, 'gene_id', train.index.get_level_values('gene_id'))\n",
    "    train.index = train.index.get_level_values('subject_id')\n",
    "\n",
    "    # boolean mask - mark True for all duplicates and original\n",
    "    duplicates_bool = train.duplicated(subset = annotation_columns, keep = False)\n",
    "    # isolate training data w/ no duplicates - complement of boolean mask\n",
    "    train_nodups = train[~duplicates_bool]\n",
    "    train_nodups.index = [train_nodups.index, train_nodups['gene_id']]\n",
    "    train_nodups = train_nodups.drop('gene_id', axis=1)\n",
    "\n",
    "    # order duplicates consecutively\n",
    "    duplicates = train[duplicates_bool].sort_values(by = annotation_columns)\n",
    "    # remove odd duplicates\n",
    "    duplicates = duplicates.groupby(by = annotation_columns).filter(lambda x: len(x) % 2 == 0)\n",
    "    duplicates.index = [duplicates.index, duplicates['gene_id']]\n",
    "    duplicates = duplicates.drop('gene_id', axis=1)\n",
    "    n1 = duplicates.iloc[::2]\n",
    "    n2 = duplicates.iloc[1::2]\n",
    "    return train_nodups, n1, n2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed all data...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tissues' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3e9830cba63c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#for group in tissue_groups:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtissue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtissues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;31m# identify tissue-specific expression data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     '''\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tissues' is not defined"
     ]
    }
   ],
   "source": [
    "# split train/test and create relevant matrices\n",
    "expression_path = '../input/expression.short.csv'\n",
    "annotations_path = '../input/g_train.csv'\n",
    "#tissue_groups_path = '../tissue_groups/tissue_groups.physiological.txt'\n",
    "tissue_groups_path = '../tissue_groups/t3.txt'\n",
    "\n",
    "train_list, test_list = [], []\n",
    "#tissues = []\n",
    "annotations = pd.read_csv(annotations_path, index_col=(0,1))\n",
    "expression = pd.read_csv(expression_path, index_col=(0,1)) \n",
    "\n",
    "tissue_groups = processTissueGroups(tissue_groups_path)\n",
    "#for k,v in tissue_groups.items():\n",
    "#    tissues.extend(v)\n",
    "annot_cols_original = list(annotations.columns)\n",
    "annot_cols_original.insert(0, 'intercept')\n",
    "# scale annotations and add intercept\n",
    "annotations = annotations / (annotations.max() - annotations.min())\n",
    "annotation_columns = list(annotations.columns)\n",
    "\n",
    "print (\"processed all data...\")\n",
    "\n",
    "#genomeonly_sharedtissue_beta = trainSharedGenomeOnlyModel(annotations, expression)\n",
    "\n",
    "#for group in tissue_groups:\n",
    "tissues \n",
    "for tissue in tissues:\n",
    "    # identify tissue-specific expression data\n",
    "    \n",
    "    expr_group = expression[tissue_groups[group]]\n",
    "    # first, limit to samples you want and take median\n",
    "    if len(expr_group.columns) == 2:\n",
    "        expr_group = expr_group.dropna()\n",
    "    elif len(expr_group.columns) == 3:\n",
    "        expr_group = expr_group.dropna(thresh = 2)\n",
    "    elif len(expr_group.columns) == 4:\n",
    "        expr_group = expr_group.dropna(thresh = 3)\n",
    "    else:\n",
    "        expr_group = expr_group.dropna(thresh = 3)\n",
    "\n",
    "    # compute med(abs(z-score)) for each sample\n",
    "    expr_group[\"expr_median\"] = np.abs(expr_group).median(axis=1)\n",
    "    \n",
    "    expr_group[\"expr_median\"] = np.abs(expression[tissue])\n",
    "    \n",
    "    # concatenate annotations with expression data\n",
    "    train = pd.concat([annotations, expr_group[\"expr_median\"]], axis = 1)\n",
    "    #train = pd.concat([annotations, expr_group[\"expr_median\"]], axis = 1)\n",
    "    \n",
    "    # drop samples with any missing annotations\n",
    "    train = train.dropna()\n",
    "    # add binarized expression label\n",
    "    train[\"expr_label\"] = sklearn.preprocessing.binarize(np.abs(train[\"expr_median\"]).reshape(-1,1), threshold = 1.5)\n",
    "    # add posterior\n",
    "    train[\"posterior\"] = 0\n",
    "    train[\"tissue\"] = str(group)\n",
    "\n",
    "    train, n1, n2 = generateTrainTest(train, annotation_columns)\n",
    "    # add intercept\n",
    "    train.insert(0, 'intercept', 1)\n",
    "    n1.insert(0, 'intercept', 1)\n",
    "    n2.insert(0, 'intercept', 1)\n",
    "\n",
    "    train_list.append(train)\n",
    "    test_list.append([n1, n2])\n",
    "\n",
    "    print (\"processed \", tissue, \" tissues.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "muscles\n"
     ]
    }
   ],
   "source": [
    "print(train_list[i][\"tissue\"].head(1).values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>intercept</th>\n",
       "      <th>max_GC_10kb</th>\n",
       "      <th>max_CpG_10kb</th>\n",
       "      <th>max_priPhCons_10kb</th>\n",
       "      <th>max_mamPhCons_10kb</th>\n",
       "      <th>max_verPhCons_10kb</th>\n",
       "      <th>max_priPhyloP_10kb</th>\n",
       "      <th>max_mamPhyloP_10kb</th>\n",
       "      <th>max_verPhyloP_10kb</th>\n",
       "      <th>max_GerpN_10kb</th>\n",
       "      <th>...</th>\n",
       "      <th>E113_EnhBiv</th>\n",
       "      <th>E116_general_promoter</th>\n",
       "      <th>E116_general_enhancer</th>\n",
       "      <th>E116_TssA</th>\n",
       "      <th>E116_TssAFlnk</th>\n",
       "      <th>E116_EnhG</th>\n",
       "      <th>E116_Enh</th>\n",
       "      <th>E116_TssBiv</th>\n",
       "      <th>E116_BivFlnk</th>\n",
       "      <th>E116_EnhBiv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_id</th>\n",
       "      <th>gene_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">GTEX-N7MS</th>\n",
       "      <th>ENSG00000001561.6</th>\n",
       "      <td>1</td>\n",
       "      <td>1.015867</td>\n",
       "      <td>0.572087</td>\n",
       "      <td>0.556651</td>\n",
       "      <td>0.560247</td>\n",
       "      <td>0.578286</td>\n",
       "      <td>0.855699</td>\n",
       "      <td>0.799545</td>\n",
       "      <td>0.672983</td>\n",
       "      <td>1.797529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000003056.3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.156892</td>\n",
       "      <td>0.592920</td>\n",
       "      <td>0.566036</td>\n",
       "      <td>0.563769</td>\n",
       "      <td>0.582093</td>\n",
       "      <td>0.903025</td>\n",
       "      <td>0.805725</td>\n",
       "      <td>0.676492</td>\n",
       "      <td>1.769976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000003402.15</th>\n",
       "      <td>1</td>\n",
       "      <td>1.451764</td>\n",
       "      <td>0.801254</td>\n",
       "      <td>0.553522</td>\n",
       "      <td>0.559807</td>\n",
       "      <td>0.577017</td>\n",
       "      <td>0.912318</td>\n",
       "      <td>0.797242</td>\n",
       "      <td>0.668350</td>\n",
       "      <td>1.863979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000004534.10</th>\n",
       "      <td>1</td>\n",
       "      <td>1.323559</td>\n",
       "      <td>0.676254</td>\n",
       "      <td>0.579444</td>\n",
       "      <td>0.584898</td>\n",
       "      <td>0.602396</td>\n",
       "      <td>0.953449</td>\n",
       "      <td>0.841063</td>\n",
       "      <td>0.704711</td>\n",
       "      <td>1.350203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000004700.11</th>\n",
       "      <td>1</td>\n",
       "      <td>1.169713</td>\n",
       "      <td>0.655420</td>\n",
       "      <td>0.581232</td>\n",
       "      <td>0.587099</td>\n",
       "      <td>0.607472</td>\n",
       "      <td>0.957493</td>\n",
       "      <td>0.843872</td>\n",
       "      <td>0.707425</td>\n",
       "      <td>1.369328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 363 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               intercept  max_GC_10kb  max_CpG_10kb  \\\n",
       "subject_id gene_id                                                    \n",
       "GTEX-N7MS  ENSG00000001561.6           1     1.015867      0.572087   \n",
       "           ENSG00000003056.3           1     1.156892      0.592920   \n",
       "           ENSG00000003402.15          1     1.451764      0.801254   \n",
       "           ENSG00000004534.10          1     1.323559      0.676254   \n",
       "           ENSG00000004700.11          1     1.169713      0.655420   \n",
       "\n",
       "                               max_priPhCons_10kb  max_mamPhCons_10kb  \\\n",
       "subject_id gene_id                                                      \n",
       "GTEX-N7MS  ENSG00000001561.6             0.556651            0.560247   \n",
       "           ENSG00000003056.3             0.566036            0.563769   \n",
       "           ENSG00000003402.15            0.553522            0.559807   \n",
       "           ENSG00000004534.10            0.579444            0.584898   \n",
       "           ENSG00000004700.11            0.581232            0.587099   \n",
       "\n",
       "                               max_verPhCons_10kb  max_priPhyloP_10kb  \\\n",
       "subject_id gene_id                                                      \n",
       "GTEX-N7MS  ENSG00000001561.6             0.578286            0.855699   \n",
       "           ENSG00000003056.3             0.582093            0.903025   \n",
       "           ENSG00000003402.15            0.577017            0.912318   \n",
       "           ENSG00000004534.10            0.602396            0.953449   \n",
       "           ENSG00000004700.11            0.607472            0.957493   \n",
       "\n",
       "                               max_mamPhyloP_10kb  max_verPhyloP_10kb  \\\n",
       "subject_id gene_id                                                      \n",
       "GTEX-N7MS  ENSG00000001561.6             0.799545            0.672983   \n",
       "           ENSG00000003056.3             0.805725            0.676492   \n",
       "           ENSG00000003402.15            0.797242            0.668350   \n",
       "           ENSG00000004534.10            0.841063            0.704711   \n",
       "           ENSG00000004700.11            0.843872            0.707425   \n",
       "\n",
       "                               max_GerpN_10kb     ...       E113_EnhBiv  \\\n",
       "subject_id gene_id                                ...                     \n",
       "GTEX-N7MS  ENSG00000001561.6         1.797529     ...               0.0   \n",
       "           ENSG00000003056.3         1.769976     ...               0.0   \n",
       "           ENSG00000003402.15        1.863979     ...               0.0   \n",
       "           ENSG00000004534.10        1.350203     ...               0.0   \n",
       "           ENSG00000004700.11        1.369328     ...               0.0   \n",
       "\n",
       "                               E116_general_promoter  E116_general_enhancer  \\\n",
       "subject_id gene_id                                                            \n",
       "GTEX-N7MS  ENSG00000001561.6                     0.0                    0.0   \n",
       "           ENSG00000003056.3                     0.0                    0.0   \n",
       "           ENSG00000003402.15                    1.0                    0.0   \n",
       "           ENSG00000004534.10                    1.0                    0.0   \n",
       "           ENSG00000004700.11                    0.0                    0.0   \n",
       "\n",
       "                               E116_TssA  E116_TssAFlnk  E116_EnhG  E116_Enh  \\\n",
       "subject_id gene_id                                                             \n",
       "GTEX-N7MS  ENSG00000001561.6         0.0            0.0        0.0       0.0   \n",
       "           ENSG00000003056.3         0.0            0.0        0.0       0.0   \n",
       "           ENSG00000003402.15        1.0            0.0        0.0       0.0   \n",
       "           ENSG00000004534.10        1.0            1.0        0.0       0.0   \n",
       "           ENSG00000004700.11        0.0            0.0        0.0       0.0   \n",
       "\n",
       "                               E116_TssBiv  E116_BivFlnk  E116_EnhBiv  \n",
       "subject_id gene_id                                                     \n",
       "GTEX-N7MS  ENSG00000001561.6           0.0           0.0          0.0  \n",
       "           ENSG00000003056.3           0.0           0.0          0.0  \n",
       "           ENSG00000003402.15          0.0           0.0          0.0  \n",
       "           ENSG00000004534.10          0.0           0.0          0.0  \n",
       "           ENSG00000004700.11          0.0           0.0          0.0  \n",
       "\n",
       "[5 rows x 363 columns]"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list[0][annot_cols_original].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adipose_Visceral_Omentum\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1671.066325\n",
      "         Iterations: 117\n",
      "         Function evaluations: 200\n",
      "         Gradient evaluations: 200\n",
      "completed training.\n",
      "all features:  0.658536585366\n",
      "Artery_Aorta\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 5860.696895\n",
      "         Iterations: 174\n",
      "         Function evaluations: 257\n",
      "         Gradient evaluations: 257\n",
      "completed training.\n",
      "all features:  0.515502798473\n",
      "Cells_Transformed_fibroblasts\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 6074.179080\n",
      "         Iterations: 159\n",
      "         Function evaluations: 254\n",
      "         Gradient evaluations: 254\n",
      "completed training.\n",
      "all features:  0.492514124294\n",
      "Colon_Transverse\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 3623.296987\n",
      "         Iterations: 148\n",
      "         Function evaluations: 228\n",
      "         Gradient evaluations: 228\n",
      "completed training.\n",
      "all features:  0.523544800523\n",
      "Esophagus_Muscularis\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 5423.238280\n",
      "         Iterations: 143\n",
      "         Function evaluations: 218\n",
      "         Gradient evaluations: 218\n",
      "completed training.\n",
      "all features:  0.528829862819\n",
      "Liver\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1781.924740\n",
      "         Iterations: 114\n",
      "         Function evaluations: 198\n",
      "         Gradient evaluations: 198\n",
      "completed training.\n",
      "all features:  0.608072916667\n",
      "Nerve_Tibial\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 7055.748765\n",
      "         Iterations: 163\n",
      "         Function evaluations: 252\n",
      "         Gradient evaluations: 252\n",
      "completed training.\n",
      "all features:  0.578984899329\n",
      "Stomach\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 3492.123999\n",
      "         Iterations: 146\n",
      "         Function evaluations: 225\n",
      "         Gradient evaluations: 225\n",
      "completed training.\n",
      "all features:  0.434934823091\n"
     ]
    }
   ],
   "source": [
    "probas_list = []\n",
    "labels_list = []\n",
    "for i in range(len(tissues)):\n",
    "    tissue = tissues[i]\n",
    "    if tissue in top_tissues:\n",
    "        print(tissue)\n",
    "        G_train = train_list[i][annot_cols_original].values\n",
    "        y_train = train_list[i][\"expr_label\"].values\n",
    "        G_test = test_list[i][0][annot_cols_original].values\n",
    "        y_test = test_list[i][1][\"expr_label\"].values\n",
    "        beta = lr.sgd(G_train, y_train, np.ones(len(G_train[0])), np.zeros(len(G_train[0])), 100)\n",
    "        print(\"completed training.\")\n",
    "        #l = sklearn.linear_model.LogisticRegression(penalty='l2', tol=.0001, fit_intercept=True)\n",
    "        #l.fit(G_train, y_train)\n",
    "        probas = lr.log_prob(G_test, beta)\n",
    "        probas_list.append(probas)\n",
    "        labels_list.append(y_test)\n",
    "        print (\"all features: \", sklearn.metrics.roc_auc_score(y_test, probas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adipose_Visceral_Omentum',\n",
       " 'Artery_Aorta',\n",
       " 'Cells_Transformed_fibroblasts',\n",
       " 'Colon_Transverse',\n",
       " 'Esophagus_Muscularis',\n",
       " 'Liver',\n",
       " 'Nerve_Tibial',\n",
       " 'Stomach']"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_tissues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tissue_groups = [['Brain_Frontal_Cortex_BA9','Brain_Cortex','Brain_Anterior_cingulate_cortex_BA24'],\n",
    "                 ['Brain_Nucleus_accumbens_basal_ganglia','Brain_Putamen_basal_ganglia','Brain_Caudate_basal_ganglia'], \n",
    "                 ['Brain_Hypothalamus','Brain_Hippocampus'],\n",
    "                 ['Heart_Atrial_Appendage','Heart_Left_Ventricle','Muscle_Skeletal'],\n",
    "                 ['Artery_Tibial', 'Artery_Aorta', 'Nerve_Tibial'],\n",
    "                 ['Skin_Not_Sun_Exposed_Suprapubic', 'Skin_Sun_Exposed_Lower_leg'],\n",
    "                 ['Lung', 'Thyroid'], ['Adipose_Visceral_Omentum', 'Adipose_Subcutaneous']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tissues_all = list(itertools.chain.from_iterable(tissue_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tissues = ['Skin_Not_Sun_Exposed_Suprapubic', 'Skin_Sun_Exposed_Lower_leg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#expr_group = expression\n",
    "#expr_group = expression[tissue]\n",
    "#expr_group = expr_group.dropna()\n",
    "#expr_group = pd.DataFrame()\n",
    "# compute med(abs(z-score)) for each sample\n",
    "expr_group = expression[tissues]\n",
    "expr_group = expr_group.dropna()\n",
    "#expr_group = expr_group.dropna(thresh = 3)\n",
    "expr_group[\"expr_median\"] = np.abs(expr_group[tissues].median(axis=1))\n",
    "#expr_group[\"expr_median\"] = np.abs(expr_group[tissue])\n",
    "# concatenate annotations with expression data\n",
    "train = pd.concat([annotations, expr_group[\"expr_median\"]], axis = 1)\n",
    "# drop samples with any missing annotations\n",
    "train = train.dropna()\n",
    "# add binarized expression label\n",
    "train[\"expr_label\"] = sklearn.preprocessing.binarize(np.abs(train[\"expr_median\"]).reshape(-1,1), threshold = 1.5)\n",
    "# add posterior\n",
    "train[\"posterior\"] = 0\n",
    "train[\"tissue\"] = str(group)\n",
    "\n",
    "train, n1, n2 = generateTrainTest(train, annotation_columns)\n",
    "# add intercept\n",
    "train.insert(0, 'intercept', 1)\n",
    "n1.insert(0, 'intercept', 1)\n",
    "n2.insert(0, 'intercept', 1)\n",
    "\n",
    "G_train = train[annot_cols_original].values\n",
    "G_train_general = train[general_features].values\n",
    "y_train = train[\"expr_label\"].values\n",
    "G_test = n1[annot_cols_original].values\n",
    "G_test_general = n1[general_features].values\n",
    "y_test = n2[\"expr_label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16615, 16615)"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "363"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 4369.962516\n",
      "         Iterations: 162\n",
      "         Function evaluations: 329\n",
      "         Gradient evaluations: 329\n"
     ]
    }
   ],
   "source": [
    "beta = lr.sgd(train[annot_cols_original].values, train[\"expr_label\"].values, np.ones(len(G_train[0])), np.zeros(len(G_train[0])), 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 15245.211842\n",
      "         Iterations: 212\n",
      "         Function evaluations: 304\n",
      "         Gradient evaluations: 304\n"
     ]
    }
   ],
   "source": [
    "beta = lr.sgd(G_train, y_train, np.ones(len(G_train[0])), np.zeros(len(G_train[0])), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 15334.047309\n",
      "         Iterations: 183\n",
      "         Function evaluations: 359\n",
      "         Gradient evaluations: 359\n"
     ]
    }
   ],
   "source": [
    "beta = lr.sgd(G_train, y_train, np.ones(len(G_train[0])), np.zeros(len(G_train[0])), 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta = lr.sgd(G_train, y_train, np.ones(len(G_train[0])), np.zeros(len(G_train[0])), 100)\n",
    "#l = sklearn.linear_model.LogisticRegression(penalty='l2', tol=.0001, fit_intercept=True)\n",
    "#l.fit(G_train, y_train)\n",
    "probas = lr.log_prob(G_test, beta)\n",
    "probas_list.append(probas)\n",
    "labels_list.append(y_test)\n",
    "print(tissue)\n",
    "print (\"all features: \", sklearn.metrics.roc_auc_score(y_test, probas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11612"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"../input/shared_beta_20tissues.txt\", beta, newline=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 8416.170137\n",
      "         Iterations: 180\n",
      "         Function evaluations: 267\n",
      "         Gradient evaluations: 267\n",
      "['Brain_Frontal_Cortex_BA9', 'Brain_Cortex', 'Brain_Anterior_cingulate_cortex_BA24']\n",
      "all features:  0.541381528923\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 9235.443678\n",
      "         Iterations: 193\n",
      "         Function evaluations: 275\n",
      "         Gradient evaluations: 275\n",
      "['Brain_Nucleus_accumbens_basal_ganglia', 'Brain_Putamen_basal_ganglia', 'Brain_Caudate_basal_ganglia']\n",
      "all features:  0.529986613119\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 8637.923319\n",
      "         Iterations: 168\n",
      "         Function evaluations: 250\n",
      "         Gradient evaluations: 250\n",
      "['Brain_Hypothalamus', 'Brain_Hippocampus']\n",
      "all features:  0.445223120695\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 34036.015781\n",
      "         Iterations: 269\n",
      "         Function evaluations: 370\n",
      "         Gradient evaluations: 370\n",
      "['Heart_Atrial_Appendage', 'Heart_Left_Ventricle', 'Muscle_Skeletal']\n",
      "all features:  0.530048048464\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 34697.098443\n",
      "         Iterations: 259\n",
      "         Function evaluations: 354\n",
      "         Gradient evaluations: 354\n",
      "['Artery_Tibial', 'Artery_Aorta', 'Nerve_Tibial']\n",
      "all features:  0.488540439011\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 36358.579458\n",
      "         Iterations: 240\n",
      "         Function evaluations: 336\n",
      "         Gradient evaluations: 336\n",
      "['Skin_Not_Sun_Exposed_Suprapubic', 'Skin_Sun_Exposed_Lower_leg']\n",
      "all features:  0.515880877717\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 36855.782360\n",
      "         Iterations: 264\n",
      "         Function evaluations: 357\n",
      "         Gradient evaluations: 357\n",
      "['Lung', 'Thyroid']\n",
      "all features:  0.531159104963\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 38415.594820\n",
      "         Iterations: 254\n",
      "         Function evaluations: 344\n",
      "         Gradient evaluations: 344\n",
      "['Adipose_Visceral_Omentum', 'Adipose_Subcutaneous']\n",
      "all features:  0.516075030865\n"
     ]
    }
   ],
   "source": [
    "probas_list, labels_list = [], []\n",
    "all_features = annot_cols_original\n",
    "general_features = all_features[0:121]\n",
    "# compute AUC for each tissue individually with and without tissue-specific annotations\n",
    "for tissue in tissue_groups:\n",
    "    #expr_group = expression\n",
    "    #expr_group = expression[tissue]\n",
    "    #expr_group = expr_group.dropna()\n",
    "    #expr_group = pd.DataFrame()\n",
    "    # compute med(abs(z-score)) for each sample\n",
    "    expr_group = expression\n",
    "    expr_group[\"expr_median\"] = np.abs(expr_group[tissue].median(axis=1))\n",
    "    #expr_group[\"expr_median\"] = np.abs(expr_group[tissue])\n",
    "    # concatenate annotations with expression data\n",
    "    train = pd.concat([annotations, expr_group[\"expr_median\"]], axis = 1)\n",
    "    # drop samples with any missing annotations\n",
    "    train = train.dropna()\n",
    "    # add binarized expression label\n",
    "    train[\"expr_label\"] = sklearn.preprocessing.binarize(np.abs(train[\"expr_median\"]).reshape(-1,1), threshold = 1.5)\n",
    "    # add posterior\n",
    "    train[\"posterior\"] = 0\n",
    "    train[\"tissue\"] = str(group)\n",
    "\n",
    "    train, n1, n2 = generateTrainTest(train, annotation_columns)\n",
    "    # add intercept\n",
    "    train.insert(0, 'intercept', 1)\n",
    "    n1.insert(0, 'intercept', 1)\n",
    "    n2.insert(0, 'intercept', 1)\n",
    "    \n",
    "    G_train = train[annot_cols_original].values\n",
    "    G_train_general = train[general_features].values\n",
    "    y_train = train[\"expr_label\"].values\n",
    "    G_test = n1[annot_cols_original].values\n",
    "    G_test_general = n1[general_features].values\n",
    "    y_test = n2[\"expr_label\"].values\n",
    "    \n",
    "    #beta = lr.sgd(G_train_list[ind], y_train_list[ind], np.ones(len(G_train_list[ind][0])), shared_beta, 10)\n",
    "    #beta = lr.sgd(G_train[:,0:121], y_train, np.ones(len(G_train[0,0:121])), np.zeros(len(G_train[0,0:121])), 100)\n",
    "    '''\n",
    "    beta = lr.sgd(G_train_general, y_train, np.ones(len(G_train_general[0])), np.zeros(len(G_train_general[0])), 100)\n",
    "    #l = sklearn.linear_model.LogisticRegression(penalty='l2', tol=.0001, fit_intercept=True)\n",
    "    #l.fit(G_train, y_train)\n",
    "    probas = lr.log_prob(G_test_general, beta)\n",
    "    probas_list.append(probas)\n",
    "    labels_list.append(y_test)\n",
    "    print(tissue)\n",
    "    print (\"general features only: \", sklearn.metrics.roc_auc_score(y_test, probas))\n",
    "    '''\n",
    "    beta = lr.sgd(G_train, y_train, np.ones(len(G_train[0])), np.zeros(len(G_train[0])), 100)\n",
    "    #l = sklearn.linear_model.LogisticRegression(penalty='l2', tol=.0001, fit_intercept=True)\n",
    "    #l.fit(G_train, y_train)\n",
    "    probas = lr.log_prob(G_test, beta)\n",
    "    probas_list.append(probas)\n",
    "    labels_list.append(y_test)\n",
    "    print(tissue)\n",
    "    print (\"all features: \", sklearn.metrics.roc_auc_score(y_test, probas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "451"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed  muscles  tissues.\n"
     ]
    }
   ],
   "source": [
    "#tissues = ['Brain_Frontal_Cortex_BA9', 'Brain_Cortex', 'Brain_Anterior_cingulate_cortex_BA24']\n",
    "#tissues = ['Brain_Nucleus_accumbens_basal_ganglia', 'Brain_Putamen_basal_ganglia', 'Brain_Caudate_basal_ganglia']\n",
    "#tissues = ['Brain_Hypothalamus', 'Brain_Hippocampus']\n",
    "#tissues = ['Heart_Atrial_Appendage','Heart_Left_Ventricle','Muscle_Skeletal']\n",
    "#tissues = ['Artery_Tibial', 'Artery_Aorta', 'Nerve_Tibial']\n",
    "#tissues = ['Skin_Not_Sun_Exposed_Suprapubic', 'Skin_Sun_Exposed_Lower_leg']\n",
    "tissues = ['Testis']\n",
    "expr_group = expression[tissues]\n",
    "expr_group = expr_group.dropna()\n",
    "#expr_group = expression[tissue_groups[\"brain\"]]\n",
    "#expr_group = expression\n",
    "# first, limit to samples you want and take median\n",
    "'''\n",
    "if len(expr_group.columns) == 2:\n",
    "    expr_group = expr_group.dropna()\n",
    "elif len(expr_group.columns) == 3:\n",
    "    expr_group = expr_group.dropna(thresh = 2)\n",
    "elif len(expr_group.columns) == 4:\n",
    "    expr_group = expr_group.dropna(thresh = 3)\n",
    "else:\n",
    "    expr_group = expr_group.dropna(thresh = 3)\n",
    "'''\n",
    "# compute med(abs(z-score)) for each sample\n",
    "expr_group[\"expr_median\"] = np.abs(expr_group).median(axis=1)\n",
    "# concatenate annotations with expression data\n",
    "train = pd.concat([annotations, expr_group[\"expr_median\"]], axis = 1)\n",
    "# drop samples with any missing annotations\n",
    "train = train.dropna()\n",
    "# add binarized expression label\n",
    "train[\"expr_label\"] = sklearn.preprocessing.binarize(np.abs(train[\"expr_median\"]).reshape(-1,1), threshold = 2.0)\n",
    "# add posterior\n",
    "train[\"posterior\"] = 0\n",
    "train[\"tissue\"] = str(group)\n",
    "\n",
    "train, n1, n2 = generateTrainTest(train, annotation_columns)\n",
    "# add intercept\n",
    "train.insert(0, 'intercept', 1)\n",
    "n1.insert(0, 'intercept', 1)\n",
    "n2.insert(0, 'intercept', 1)\n",
    "\n",
    "#train_list.append(train)\n",
    "#test_list.append([n1, n2])\n",
    "train_list[11] = train\n",
    "test_list[11] = [n1, n2]\n",
    "print (\"processed \", group, \" tissues.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60987"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_list[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2193"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_list[11][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.append(y_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G_train_list, y_train_list, G_test_list, y_test_list = [], [], [], []\n",
    "tissue_indices = [6, 4, 7, 8, 9, 10]\n",
    "for ind in tissue_indices:\n",
    "    G_train_list.append(train_list[ind][annot_cols_original].values)\n",
    "    y_train_list.append(train_list[ind][\"expr_label\"].values)\n",
    "    G_test_list.append(test_list[ind][0][annot_cols_original].values)\n",
    "    y_test_list.append(test_list[ind][1][\"expr_label\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_train = np.append(G_train1, G_train2, axis=0)\n",
    "G_train = np.append(G_train, G_train3, axis=0)\n",
    "G_train = np.append(G_train, G_train4, axis=0)\n",
    "G_train = np.append(G_train, G_train5, axis=0)\n",
    "G_train = np.append(G_train, G_train6, axis=0)\n",
    "\n",
    "\n",
    "G_test = np.append(G_test1, G_test2, axis=0)\n",
    "G_test = np.append(G_test, G_test3, axis=0)\n",
    "G_test = np.append(G_test, G_test4, axis=0)\n",
    "G_test = np.append(G_test, G_test5, axis=0)\n",
    "G_test = np.append(G_test, G_test6, axis=0)\n",
    "\n",
    "\n",
    "y_train = np.append(y_train1, y_train2)\n",
    "y_train = np.append(y_train, y_train3)\n",
    "y_train = np.append(y_train, y_train4)\n",
    "y_train = np.append(y_train, y_train5)\n",
    "y_train = np.append(y_train, y_train6)\n",
    "\n",
    "\n",
    "y_test = np.append(y_test1, y_test2)\n",
    "y_test = np.append(y_test,y_test3)\n",
    "y_test = np.append(y_test,y_test4)\n",
    "y_test = np.append(y_test,y_test5)\n",
    "y_test = np.append(y_test,y_test6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G_train = train_list[11][annot_cols_original].values\n",
    "y_train = train_list[11][\"expr_label\"].values\n",
    "G_test = test_list[11][0][annot_cols_original].values\n",
    "y_test = test_list[11][1][\"expr_label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2193"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2193,)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 23919.452449\n",
      "         Iterations: 219\n",
      "         Function evaluations: 307\n",
      "         Gradient evaluations: 307\n",
      "completed training.\n"
     ]
    }
   ],
   "source": [
    "#beta = lr.sgd(G_train_list[ind], y_train_list[ind], np.ones(len(G_train_list[ind][0])), shared_beta, 10)\n",
    "#beta = lr.sgd(G_train[:,0:121], y_train, np.ones(len(G_train[0,0:121])), np.zeros(len(G_train[0,0:121])), 100)\n",
    "beta = lr.sgd(G_train, y_train, np.ones(len(G_train[0])), np.zeros(len(G_train[0])), 100)\n",
    "\n",
    "print(\"completed training.\")\n",
    "#l = sklearn.linear_model.LogisticRegression(penalty='l2', tol=.0001, fit_intercept=True)\n",
    "#l.fit(G_train, y_train)\n",
    "probas = lr.log_prob(G_test, beta)\n",
    "probas_list.append(probas)\n",
    "labels_list.append(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2193"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 6652.002673\n",
      "         Iterations: 168\n",
      "         Function evaluations: 252\n",
      "         Gradient evaluations: 252\n",
      "completed training.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 7240.150341\n",
      "         Iterations: 176\n",
      "         Function evaluations: 258\n",
      "         Gradient evaluations: 258\n",
      "completed training.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 5349.207600\n",
      "         Iterations: 166\n",
      "         Function evaluations: 244\n",
      "         Gradient evaluations: 244\n",
      "completed training.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-281-f0d5f531a1e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtissue_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#beta = lr.sgd(G_train_list[ind], y_train_list[ind], np.ones(len(G_train_list[ind][0])), shared_beta, 10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_train_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_train_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_train_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"completed training.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/farhan.damani/Google Drive/computer_backup/Research/src/rare_variants_shared/src/models/int_model/tissue_spec_tl/notebooks/logistic_regression.py\u001b[0m in \u001b[0;36msgd\u001b[0;34m(G, Q, beta_c, beta_parent, lambda_hp)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mvY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mlambda_hp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlambda_hp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mbeta_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmin_bfgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cost_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvBeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfprime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_gradient_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvBetaParent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_hp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgtol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbeta_c\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/farhan.damani/anaconda3/lib/python3.5/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfmin_bfgs\u001b[0;34m(f, x0, fprime, args, gtol, norm, epsilon, maxiter, full_output, disp, retall, callback)\u001b[0m\n\u001b[1;32m    791\u001b[0m             'return_all': retall}\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_minimize_bfgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfprime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/farhan.damani/anaconda3/lib/python3.5/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_minimize_bfgs\u001b[0;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, **unknown_options)\u001b[0m\n\u001b[1;32m    863\u001b[0m             \u001b[0malpha_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgfkp1\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m                      _line_search_wolfe12(f, myfprime, xk, pk, gfk,\n\u001b[0;32m--> 865\u001b[0;31m                                           old_fval, old_old_fval)\n\u001b[0m\u001b[1;32m    866\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_LineSearchError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m             \u001b[0;31m# Line search failed to find a better solution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/farhan.damani/anaconda3/lib/python3.5/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_line_search_wolfe12\u001b[0;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, **kwargs)\u001b[0m\n\u001b[1;32m    697\u001b[0m     ret = line_search_wolfe1(f, fprime, xk, pk, gfk,\n\u001b[1;32m    698\u001b[0m                              \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                              **kwargs)\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/farhan.damani/anaconda3/lib/python3.5/site-packages/scipy/optimize/linesearch.py\u001b[0m in \u001b[0;36mline_search_wolfe1\u001b[0;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, args, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[1;32m     99\u001b[0m     stp, fval, old_fval = scalar_search_wolfe1(\n\u001b[1;32m    100\u001b[0m             \u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderphi0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             c1=c1, c2=c2, amax=amax, amin=amin, xtol=xtol)\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/farhan.damani/anaconda3/lib/python3.5/site-packages/scipy/optimize/linesearch.py\u001b[0m in \u001b[0;36mscalar_search_wolfe1\u001b[0;34m(phi, derphi, phi0, old_phi0, derphi0, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb'FG'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0malpha1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0mphi1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m             \u001b[0mderphi1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mderphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/farhan.damani/anaconda3/lib/python3.5/site-packages/scipy/optimize/linesearch.py\u001b[0m in \u001b[0;36mphi\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mfc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mderphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/farhan.damani/anaconda3/lib/python3.5/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/farhan.damani/Google Drive/computer_backup/Research/src/rare_variants_shared/src/models/int_model/tissue_spec_tl/notebooks/logistic_regression.py\u001b[0m in \u001b[0;36m_cost_function\u001b[0;34m(vBeta, vBetaParent, mX, vY, lambda_hp)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_cost_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvBeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvBetaParent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_hp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# cost function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mxr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvY\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvBeta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvBeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mvY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvBeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlambda_hp\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvBeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvBetaParent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvBeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvBetaParent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;31m# incur penalty from features excluding intercept\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m#xr += .5 * lambda_hp * (vBeta[1:] - vBetaParent[1:]).dot((vBeta[1:] - vBetaParent[1:]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "labels_list, probas_list = [], []\n",
    "for ind in range(len(tissue_indices)):\n",
    "    #beta = lr.sgd(G_train_list[ind], y_train_list[ind], np.ones(len(G_train_list[ind][0])), shared_beta, 10)\n",
    "    beta = lr.sgd(G_train_list[ind], y_train_list[ind], np.ones(len(G_train_list[ind][0])), np.zeros(len(G_train_list[ind][0])), 100)\n",
    "\n",
    "    print(\"completed training.\")\n",
    "    #l = sklearn.linear_model.LogisticRegression(penalty='l2', tol=.0001, fit_intercept=True)\n",
    "    #l.fit(G_train, y_train)\n",
    "    probas = lr.log_prob(G_test_list[ind], beta)\n",
    "    probas_list.append(probas)\n",
    "    labels_list.append(y_test_list[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bootstrap_resample(X, n=None):\n",
    "    \"\"\" \n",
    "    citation: http://nbviewer.jupyter.org/gist/aflaxman/6871948\n",
    "    Bootstrap resample an array_like\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array_like\n",
    "      data to resample\n",
    "    n : int, optional\n",
    "      length of resampled array, equal to len(X) if n==None\n",
    "    Results\n",
    "    -------\n",
    "    returns X_resamples\n",
    "    \"\"\"\n",
    "    if n == None:\n",
    "        n = len(X)\n",
    "        \n",
    "    resample_i = np.floor(np.random.rand(n)*len(X)).astype(int)\n",
    "    X_resample = X.iloc[resample_i]\n",
    "    return X_resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimateBeta(beta):\n",
    "    for i in range(self.num_tissues):\n",
    "        self.beta_children[i] = lr.sgd(self.train_list[i][self.genomic_features], self.train_list[i]['posterior'], self.getBetaLeaf(i), self.beta_parent, self.lambda_hp_children[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimateBetaParent(beta_children, lambda_hp_children, lambda_hp_parent, num_tissues):\n",
    "    '''\n",
    "        Estimate beta parent \n",
    "        beta_j = (2 * \\sum_c lambda^c * beta_j^c) / (2*lamda + L * \\sum_c lambda^c)\n",
    "    '''\n",
    "\n",
    "    return (2 * np.sum((np.array([lambda_hp_children]).T * beta_children), axis = 0)) / (2 * \n",
    "        lambda_hp_parent + num_tissues * np.sum(lambda_hp_children))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta_parent = estimateBetaParent(beta, np.ones(num_tissues), 0.01, num_tissues)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "K = 100\n",
    "num_tissues = len(train_list)\n",
    "# beta is a T x M matrix, where T = # of tissues and M = number of features (not including intercept)\n",
    "beta = np.zeros((num_tissues, len(annot_cols_original) - 1))\n",
    "beta_parent = np.zeros(len(annot_cols_original) - 1)\n",
    "\n",
    "delta = np.zeros((K, num_tissues, len(annot_cols_original) - 1))\n",
    "# for 1 to K sampled datasets\n",
    "for i in range(K):\n",
    "    print(i)\n",
    "    # for each tissue\n",
    "    for j in range(num_tissues):\n",
    "        train_sample = bootstrap_resample(train_list[j])\n",
    "        \n",
    "        for k in range(len(annot_cols_original)):\n",
    "            if annot_cols_original[k] == 'intercept':\n",
    "                continue\n",
    "            g = train_sample[['intercept', annot_cols_original[k]]]\n",
    "            expr_label = train_sample[\"expr_label\"]\n",
    "            beta[j][k-1] = lr.sgd(g, expr_label, np.zeros(2), np.zeros(2), 1)[1]\n",
    "    beta_parent = estimateBetaParent(beta, np.ones(num_tissues), 0.01, num_tissues)\n",
    "    \n",
    "    # estimate variance between each beta child and beta parent for this trial\n",
    "    for j in range(num_tissues):\n",
    "        delta[i][j] = (beta[j] - beta_parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeEmpiricalVariance(delta):\n",
    "    lambda_hp = np.zeros((num_tissues, len(annot_cols_original) - 1))\n",
    "    for t in range(num_tissues):\n",
    "        for j in range(len(annot_cols_original) - 1):\n",
    "            lambda_hp[t][j] = np.sum(delta[:,t,j]**2) / float(len(annot_cols_original) - 1 - 1)\n",
    "    return lambda_hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lambda_hp = computeEmpiricalVariance(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 41.74163529,  25.14222397,  35.58924862,  25.01939031])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(lambda_hp, axis=1)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
