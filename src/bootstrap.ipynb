{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "import logistic_regression as lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# v7\n",
    "g = pd.read_csv('../../../../../../data/train/train_all_g.csv', index_col=(0,1))\n",
    "e = pd.read_csv('../../../../../../data/train/train_all_tissues.csv', index_col=(0,1)).dropna(thresh = 3)\n",
    "train = pd.concat([g,e[\"median\"]], axis = 1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# v6p with tissue-specific annotations\n",
    "g = pd.read_csv('../input/g_train.csv', index_col=(0,1))\n",
    "e = pd.read_csv('../input/expression.short.csv', index_col=(0,1))\n",
    "train = pd.concat([g,e[\"median\"]], axis = 1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add discrete training labels\n",
    "train[\"labels\"] = sklearn.preprocessing.binarize(np.abs(train[\"median\"].values).reshape(-1,1), threshold = 1.5).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### processing data helper functions #####\n",
    "def processTissueGroups(tissue_groups_path):\n",
    "    tissue_groups = {}\n",
    "    f = open(tissue_groups_path)\n",
    "    for l in f:\n",
    "        w = l.strip().split(',')\n",
    "        group = w[0]\n",
    "        tissue_groups[group] = []\n",
    "        for tissue in w[1:]: tissue_groups[group].append(tissue)\n",
    "    return tissue_groups    \n",
    "    \n",
    "\n",
    "def generateTrainTest(train, annotation_columns):\n",
    "    '''\n",
    "        Training data contains annotation columns and other data columns\n",
    "        annotation_columns is a list of genomic annotations\n",
    "    '''\n",
    "    annotation_columns.insert(0, 'gene_id')\n",
    "    train.insert(0, 'gene_id', train.index.get_level_values('gene_id'))\n",
    "    train.index = train.index.get_level_values('subject_id')\n",
    "\n",
    "    # boolean mask - mark True for all duplicates and original\n",
    "    duplicates_bool = train.duplicated(subset = annotation_columns, keep = False)\n",
    "    # isolate training data w/ no duplicates - complement of boolean mask\n",
    "    train_nodups = train[~duplicates_bool]\n",
    "    train_nodups.index = [train_nodups.index, train_nodups['gene_id']]\n",
    "    train_nodups = train_nodups.drop('gene_id', axis=1)\n",
    "\n",
    "    # order duplicates consecutively\n",
    "    duplicates = train[duplicates_bool].sort_values(by = annotation_columns)\n",
    "    # remove odd duplicates\n",
    "    duplicates = duplicates.groupby(by = annotation_columns).filter(lambda x: len(x) % 2 == 0)\n",
    "    duplicates.index = [duplicates.index, duplicates['gene_id']]\n",
    "    duplicates = duplicates.drop('gene_id', axis=1)\n",
    "    n1 = duplicates.iloc[::2]\n",
    "    n2 = duplicates.iloc[1::2]\n",
    "    return train_nodups, n1, n2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed all data...\n",
      "processed  muscle  tissues.\n",
      "processed  epithelial  tissues.\n",
      "processed  digestive  tissues.\n",
      "processed  brain  tissues.\n",
      "processed  group1  tissues.\n"
     ]
    }
   ],
   "source": [
    "# split train/test and create relevant matrices\n",
    "#expression_path = '../../../../../../data/train/train_all_tissues.csv'\n",
    "#annotations_path = '../../../../../../data/train/train_all_g.csv'\n",
    "#tissue_groups_path = '../tissue_groups/tissue_groups.v7.txt'\n",
    "\n",
    "\n",
    "# v6p\n",
    "expression_path = '../input/expression.short.csv'\n",
    "annotations_path = '../input/g_train.csv'\n",
    "tissue_groups_path = '../tissue_groups/t3.txt'\n",
    "\n",
    "\n",
    "train_list, test_list = [], []\n",
    "tissues = []\n",
    "annotations = pd.read_csv(annotations_path, index_col=(0,1))\n",
    "expression = pd.read_csv(expression_path, index_col=(0,1)) \n",
    "\n",
    "tissue_groups = processTissueGroups(tissue_groups_path)\n",
    "for k,v in tissue_groups.items():\n",
    "    tissues.extend(v)\n",
    "annot_cols_original = list(annotations.columns)\n",
    "annot_cols_original.insert(0, 'intercept')\n",
    "# scale annotations and add intercept\n",
    "annotations = annotations / (annotations.max() - annotations.min())\n",
    "annotation_columns = list(annotations.columns)\n",
    "\n",
    "print (\"processed all data...\")\n",
    "\n",
    "#genomeonly_sharedtissue_beta = trainSharedGenomeOnlyModel(annotations, expression)\n",
    "\n",
    "for group in tissue_groups:\n",
    "    # identify tissue-specific expression data\n",
    "    expr_group = expression[tissue_groups[group]]\n",
    "    # first, limit to samples you want and take median\n",
    "    if group == 'brain':\n",
    "        expr_group = expr_group.dropna(thresh = 3)\n",
    "    elif group == 'group1':\n",
    "        expr_group = expr_group.dropna(thresh = 4)\n",
    "    elif len(tissue_groups[group]) == 1:\n",
    "        expr_group = expr_group.dropna()\n",
    "    else:\n",
    "        expr_group = expr_group.dropna(thresh = 2)\n",
    "\n",
    "\n",
    "    # compute med(abs(z-score)) for each sample\n",
    "    expr_group[\"expr_median\"] = np.abs(expr_group).median(axis=1)\n",
    "    # concatenate annotations with expression data\n",
    "    train = pd.concat([annotations, expr_group[\"expr_median\"]], axis = 1)\n",
    "    # drop samples with any missing annotations\n",
    "    train = train.dropna()\n",
    "\n",
    "    # add binarized expression label\n",
    "    train[\"expr_label\"] = sklearn.preprocessing.binarize(np.abs(train[\"expr_median\"]).reshape(-1,1), threshold = 1.5)\n",
    "    # add posterior\n",
    "    train[\"posterior\"] = 0\n",
    "    train[\"tissue\"] = str(group)\n",
    "\n",
    "    train, n1, n2 = generateTrainTest(train, annotation_columns)\n",
    "    # add intercept\n",
    "    train.insert(0, 'intercept', 1)\n",
    "    n1.insert(0, 'intercept', 1)\n",
    "    n2.insert(0, 'intercept', 1)\n",
    "\n",
    "    train_list.append(train)\n",
    "    test_list.append([n1, n2])\n",
    "\n",
    "    print (\"processed \", group, \" tissues.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_list, tissues = [], []\n",
    "annotations_path = '../input/g_train.csv'\n",
    "expression_path = '../input/simulated_data/multitask_with_transfer_v2/e.csv'\n",
    "tissue_groups_path = '../tissue_groups/t3.txt'\n",
    "annotations = pd.read_csv(annotations_path)\n",
    "annotations = annotations.drop(\"subject_id\", axis=1)\n",
    "annotations = annotations.drop(\"gene_id\", axis=1)\n",
    "expression = pd.read_csv(expression_path, index_col=(0))\n",
    "tissue_groups = processTissueGroups(tissue_groups_path)\n",
    "for k,v in tissue_groups.items():\n",
    "    tissues.extend(v)\n",
    "annot_cols_original = list(annotations.columns)\n",
    "annot_cols_original.insert(0, 'intercept')\n",
    "# scale annotations and add intercept\n",
    "annotations = annotations / (annotations.max() - annotations.min())\n",
    "annotation_columns = list(annotations.columns)\n",
    "c = 0\n",
    "\n",
    "for group in tissue_groups:\n",
    "    expr = expression[group]\n",
    "    expr.name = 'expression'\n",
    "\n",
    "    # concatenate annotations with expression data\n",
    "    train = pd.concat([annotations, expr], axis=1).dropna()\n",
    "\n",
    "    train[\"expr_label\"] = expr\n",
    "    # add posterior\n",
    "    train[\"posterior\"] = 0\n",
    "    train[\"tissue\"] = str(group)\n",
    "    # add intercept\n",
    "    train.insert(0, 'intercept', 1)\n",
    "    train_list.append(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epithelial\n",
      "digestive\n",
      "group1\n",
      "brain\n",
      "muscle\n"
     ]
    }
   ],
   "source": [
    "for group in tissue_groups:\n",
    "    print (group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intercept</th>\n",
       "      <th>max_CpG_10kb</th>\n",
       "      <th>max_PHRED_10kb</th>\n",
       "      <th>max_verPhCons_10kb</th>\n",
       "      <th>max_cHmmTssA_10kb</th>\n",
       "      <th>max_mamPhCons_10kb</th>\n",
       "      <th>max_verPhyloP_10kb</th>\n",
       "      <th>max_GC_10kb</th>\n",
       "      <th>max_EncOCpolIIPVal_10kb</th>\n",
       "      <th>max_TFBS_10kb</th>\n",
       "      <th>...</th>\n",
       "      <th>E110_general_promoter</th>\n",
       "      <th>E110_general_enhancer</th>\n",
       "      <th>E111_general_promoter</th>\n",
       "      <th>E111_general_enhancer</th>\n",
       "      <th>E113_general_promoter</th>\n",
       "      <th>E113_general_enhancer</th>\n",
       "      <th>expression</th>\n",
       "      <th>expr_label</th>\n",
       "      <th>posterior</th>\n",
       "      <th>tissue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.572087</td>\n",
       "      <td>0.376902</td>\n",
       "      <td>0.578286</td>\n",
       "      <td>1.010185</td>\n",
       "      <td>0.560247</td>\n",
       "      <td>0.672983</td>\n",
       "      <td>1.015867</td>\n",
       "      <td>1.184023</td>\n",
       "      <td>0.372614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>digestive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.592920</td>\n",
       "      <td>0.364608</td>\n",
       "      <td>0.582093</td>\n",
       "      <td>1.026185</td>\n",
       "      <td>0.563769</td>\n",
       "      <td>0.676492</td>\n",
       "      <td>1.156892</td>\n",
       "      <td>1.184023</td>\n",
       "      <td>0.372614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>digestive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.801254</td>\n",
       "      <td>0.388538</td>\n",
       "      <td>0.577017</td>\n",
       "      <td>1.687185</td>\n",
       "      <td>0.559807</td>\n",
       "      <td>0.668350</td>\n",
       "      <td>1.451764</td>\n",
       "      <td>1.344023</td>\n",
       "      <td>0.582698</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>digestive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.676254</td>\n",
       "      <td>0.427440</td>\n",
       "      <td>0.602396</td>\n",
       "      <td>1.018185</td>\n",
       "      <td>0.584898</td>\n",
       "      <td>0.704711</td>\n",
       "      <td>1.323559</td>\n",
       "      <td>1.184023</td>\n",
       "      <td>0.372614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>digestive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.592920</td>\n",
       "      <td>0.448680</td>\n",
       "      <td>0.583785</td>\n",
       "      <td>1.018185</td>\n",
       "      <td>0.565090</td>\n",
       "      <td>0.733772</td>\n",
       "      <td>1.323559</td>\n",
       "      <td>1.266523</td>\n",
       "      <td>0.372614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>digestive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   intercept  max_CpG_10kb  max_PHRED_10kb  max_verPhCons_10kb  \\\n",
       "0          1      0.572087        0.376902            0.578286   \n",
       "1          1      0.592920        0.364608            0.582093   \n",
       "2          1      0.801254        0.388538            0.577017   \n",
       "3          1      0.676254        0.427440            0.602396   \n",
       "4          1      0.592920        0.448680            0.583785   \n",
       "\n",
       "   max_cHmmTssA_10kb  max_mamPhCons_10kb  max_verPhyloP_10kb  max_GC_10kb  \\\n",
       "0           1.010185            0.560247            0.672983     1.015867   \n",
       "1           1.026185            0.563769            0.676492     1.156892   \n",
       "2           1.687185            0.559807            0.668350     1.451764   \n",
       "3           1.018185            0.584898            0.704711     1.323559   \n",
       "4           1.018185            0.565090            0.733772     1.323559   \n",
       "\n",
       "   max_EncOCpolIIPVal_10kb  max_TFBS_10kb    ...      E110_general_promoter  \\\n",
       "0                 1.184023       0.372614    ...                        0.0   \n",
       "1                 1.184023       0.372614    ...                        0.0   \n",
       "2                 1.344023       0.582698    ...                        1.0   \n",
       "3                 1.184023       0.372614    ...                        0.0   \n",
       "4                 1.266523       0.372614    ...                        0.0   \n",
       "\n",
       "   E110_general_enhancer  E111_general_promoter  E111_general_enhancer  \\\n",
       "0                    0.0                    0.0                    0.0   \n",
       "1                    1.0                    0.0                    0.0   \n",
       "2                    0.0                    1.0                    0.0   \n",
       "3                    0.0                    0.0                    0.0   \n",
       "4                    0.0                    0.0                    0.0   \n",
       "\n",
       "   E113_general_promoter  E113_general_enhancer  expression  expr_label  \\\n",
       "0                    0.0                    0.0           0           0   \n",
       "1                    0.0                    1.0           1           1   \n",
       "2                    1.0                    0.0           0           0   \n",
       "3                    0.0                    0.0           0           0   \n",
       "4                    0.0                    1.0           0           0   \n",
       "\n",
       "   posterior     tissue  \n",
       "0          0  digestive  \n",
       "1          0  digestive  \n",
       "2          0  digestive  \n",
       "3          0  digestive  \n",
       "4          0  digestive  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bootstrap_resample(X, n=None):\n",
    "    \"\"\" \n",
    "    citation: http://nbviewer.jupyter.org/gist/aflaxman/6871948\n",
    "    Bootstrap resample an array_like\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array_like\n",
    "      data to resample\n",
    "    n : int, optional\n",
    "      length of resampled array, equal to len(X) if n==None\n",
    "    Results\n",
    "    -------\n",
    "    returns X_resamples\n",
    "    \"\"\"\n",
    "    if n == None:\n",
    "        n = len(X)\n",
    "        \n",
    "    resample_i = np.floor(np.random.rand(n)*len(X)).astype(int)\n",
    "    X_resample = X.iloc[resample_i]\n",
    "    return X_resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimateBetaParent(beta_children, lambda_hp_children, lambda_hp_parent, num_tissues):\n",
    "    '''\n",
    "        Estimate beta parent \n",
    "        beta_j = (2 * \\sum_c lambda^c * beta_j^c) / (2*lamda + L * \\sum_c lambda^c)\n",
    "    '''\n",
    "\n",
    "    return (np.sum((np.array([lambda_hp_children]).T * beta_children), axis = 0)) / (lambda_hp_parent + np.sum(lambda_hp_children))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import metrics\n",
    "def _cross_validate(g, expr_label, beta_init, beta_parent_init, lambda_set):\n",
    "    '''\n",
    "        Cross-validate beta MAP estimation to find optimal lambda\n",
    "    '''\n",
    "    X = g\n",
    "    Y = expr_label\n",
    "    K = 5\n",
    "    scores_list = np.zeros((len(lambda_set), K))\n",
    "    for k in range(K):\n",
    "        training = np.array([x for i, x in enumerate(X) if i % K != k])\n",
    "        training_labels = np.array([x for i, x in enumerate(Y) if i % K != k])\n",
    "        validation = np.array([[x for i, x in enumerate(X) if i % K == k]])\n",
    "        validation_labels = np.array([x for i, x in enumerate(Y) if i % K == k])\n",
    "        for i in range(len(lambda_set)):\n",
    "            beta = lr.sgd(training, training_labels, beta_init, beta_parent_init, float(lambda_set[i]))\n",
    "            scores = lr.log_prob(validation, beta).reshape(-1)\n",
    "            auc = sklearn.metrics.roc_auc_score(validation_labels, scores)\n",
    "            print(lambda_set[i], auc)\n",
    "            scores_list[i][k] = auc\n",
    "    # average across all folds for each lambda\n",
    "    lambda_averages = np.mean(scores_list, axis=1)\n",
    "    print(lambda_averages)\n",
    "    # sanity check\n",
    "    assert len(lambda_averages) == len(lambda_set)\n",
    "    optimal_lambda = lambda_set[np.argmax(lambda_averages)]\n",
    "    return optimal_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.0, 1.0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tissue:  0\n",
      "1e-06 0.55247783832\n",
      "1e-05 0.552477814156\n",
      "0.0001 0.552477875664\n",
      "0.001 0.55247813048\n",
      "0.01 0.552485096176\n",
      "0.1 0.552550370753\n",
      "1.0 0.552753498471\n",
      "10.0 0.552772038516\n",
      "100.0 0.552702779147\n",
      "1000.0 0.550747210813\n",
      "10000.0 0.537922989364\n",
      "100000.0 0.530513416543\n",
      "1000000.0 0.529555878148\n",
      "1e-06 0.554340640888\n",
      "1e-05 0.554340763163\n",
      "0.0001 0.554341429127\n",
      "0.001 0.554340791548\n",
      "0.01 0.554348239431\n",
      "0.1 0.554399132204\n",
      "1.0 0.554570081965\n",
      "10.0 0.55454205906\n",
      "100.0 0.553064541932\n",
      "1000.0 0.547593819893\n",
      "10000.0 0.536102492369\n",
      "100000.0 0.529345716846\n",
      "1000000.0 0.528338357412\n",
      "1e-06 0.54941830458\n",
      "1e-05 0.549418313341\n",
      "0.0001 0.549418330862\n",
      "0.001 0.549417478907\n",
      "0.01 0.549408280431\n",
      "0.1 0.549334033399\n",
      "1.0 0.549253130612\n",
      "10.0 0.549405512128\n",
      "100.0 0.549471850661\n",
      "1000.0 0.546927298127\n",
      "10000.0 0.537794797032\n",
      "100000.0 0.531654989464\n",
      "1000000.0 0.530615855143\n",
      "1e-06 0.556816765021\n",
      "1e-05 0.556816815329\n",
      "0.0001 0.55681670815\n",
      "0.001 0.556815949144\n",
      "0.01 0.556816988129\n",
      "0.1 0.556792225293\n",
      "1.0 0.556882686968\n",
      "10.0 0.557008786916\n",
      "100.0 0.556087189874\n",
      "1000.0 0.551308787096\n",
      "10000.0 0.539897728283\n",
      "100000.0 0.531045597234\n",
      "1000000.0 0.529862331317\n",
      "1e-06 0.551565927126\n",
      "1e-05 0.551565995307\n",
      "0.0001 0.55156632961\n",
      "0.001 0.551567818581\n",
      "0.01 0.551571799432\n",
      "0.1 0.55160399154\n",
      "1.0 0.551949272082\n",
      "10.0 0.552431379531\n",
      "100.0 0.552459762339\n",
      "1000.0 0.548010611497\n",
      "10000.0 0.537855973031\n",
      "100000.0 0.531891006499\n",
      "1000000.0 0.530755944912\n",
      "[ 0.5529239   0.55292394  0.55292413  0.55292403  0.55292608  0.55293595\n",
      "  0.55308173  0.55323196  0.55275722  0.54891755  0.5379148   0.53089015\n",
      "  0.52982567]\n",
      "tissue:  1\n",
      "1e-06 0.539563837148\n",
      "1e-05 0.539563793697\n",
      "0.0001 0.539562965427\n",
      "0.001 0.539554829372\n",
      "0.01 0.539531884935\n",
      "0.1 0.539537443849\n",
      "1.0 0.539666064675\n",
      "10.0 0.540257248495\n",
      "100.0 0.54079043169\n",
      "1000.0 0.539549607197\n",
      "10000.0 0.533326575736\n",
      "100000.0 0.527621204876\n",
      "1000000.0 0.525727847555\n",
      "1e-06 0.54488393708\n",
      "1e-05 0.544883741851\n",
      "0.0001 0.544883370372\n",
      "0.001 0.54488059377\n",
      "0.01 0.544884709865\n",
      "0.1 0.54492332198\n",
      "1.0 0.545004702977\n",
      "10.0 0.544833830811\n",
      "100.0 0.54382203071\n",
      "1000.0 0.538209938776\n",
      "10000.0 0.528939574014\n",
      "100000.0 0.521938085864\n",
      "1000000.0 0.520013849493\n",
      "1e-06 0.53107357349\n",
      "1e-05 0.531081290443\n",
      "0.0001 0.531136191982\n",
      "0.001 0.531305858665\n",
      "0.01 0.531373395623\n",
      "0.1 0.531402099853\n",
      "1.0 0.531227035118\n",
      "10.0 0.530367090851\n",
      "100.0 0.529860630421\n",
      "1000.0 0.530383317706\n",
      "10000.0 0.526524958641\n",
      "100000.0 0.522561417949\n",
      "1000000.0 0.522217013522\n",
      "1e-06 0.544260778317\n",
      "1e-05 0.544260596483\n",
      "0.0001 0.544261011716\n",
      "0.001 0.544262797491\n",
      "0.01 0.544274296465\n",
      "0.1 0.544323614231\n",
      "1.0 0.544466245485\n",
      "10.0 0.545308501294\n",
      "100.0 0.546340714088\n",
      "1000.0 0.544902897141\n",
      "10000.0 0.539821669219\n",
      "100000.0 0.53334203351\n",
      "1000000.0 0.531174347832\n",
      "1e-06 0.534646700718\n",
      "1e-05 0.534647073711\n",
      "0.0001 0.534659828974\n",
      "0.001 0.534697629204\n",
      "0.01 0.534730101354\n",
      "0.1 0.534791971867\n",
      "1.0 0.534858952654\n",
      "10.0 0.534703063463\n",
      "100.0 0.53454619959\n",
      "1000.0 0.531739442726\n",
      "10000.0 0.528661057291\n",
      "100000.0 0.525054623019\n",
      "1000000.0 0.523547958265\n",
      "[ 0.53888577  0.5388873   0.53890067  0.53894034  0.53895888  0.53899569\n",
      "  0.5390446   0.53909395  0.539072    0.53695704  0.53145477  0.52610347\n",
      "  0.5245362 ]\n",
      "tissue:  2\n",
      "1e-06 0.586019677507\n",
      "1e-05 0.586019657817\n",
      "0.0001 0.586019786897\n",
      "0.001 0.586019911601\n",
      "0.01 0.586017305934\n",
      "0.1 0.585987901934\n",
      "1.0 0.585939230001\n",
      "10.0 0.585984351139\n",
      "100.0 0.58597599594\n",
      "1000.0 0.584196649208\n",
      "10000.0 0.575676059214\n",
      "100000.0 0.564259582168\n",
      "1000000.0 0.560568955758\n",
      "1e-06 0.580359212597\n",
      "1e-05 0.580359291549\n",
      "0.0001 0.580359388046\n",
      "0.001 0.580359940707\n",
      "0.01 0.580366912579\n",
      "0.1 0.58043728265\n",
      "1.0 0.580754400843\n",
      "10.0 0.581069507962\n",
      "100.0 0.58089954912\n",
      "1000.0 0.578628041312\n",
      "10000.0 0.569790512684\n",
      "100000.0 0.558955127155\n",
      "1000000.0 0.555196836406\n",
      "1e-06 0.581840674124\n",
      "1e-05 0.581840671933\n",
      "0.0001 0.581840704798\n",
      "0.001 0.581841235031\n",
      "0.01 0.581846581179\n",
      "0.1 0.581901471223\n",
      "1.0 0.582177577872\n",
      "10.0 0.582896643581\n",
      "100.0 0.583337157436\n",
      "1000.0 0.581932152418\n",
      "10000.0 0.574848030476\n",
      "100000.0 0.562146278891\n",
      "1000000.0 0.556933635317\n",
      "1e-06 0.575789487012\n",
      "1e-05 0.575788373509\n",
      "0.0001 0.575780122774\n",
      "0.001 0.575746471191\n",
      "0.01 0.575715682285\n",
      "0.1 0.575704599144\n",
      "1.0 0.575702482407\n",
      "10.0 0.575485217377\n",
      "100.0 0.575183092587\n",
      "1000.0 0.573604996825\n",
      "10000.0 0.565666384403\n",
      "100000.0 0.555814970108\n",
      "1000000.0 0.552688462635\n",
      "1e-06 0.578229934801\n",
      "1e-05 0.578229878696\n",
      "0.0001 0.57822992617\n",
      "0.001 0.578230148431\n",
      "0.01 0.578235348915\n",
      "0.1 0.578275949374\n",
      "1.0 0.578614826718\n",
      "10.0 0.579378713073\n",
      "100.0 0.579508194333\n",
      "1000.0 0.576447601639\n",
      "10000.0 0.56709587131\n",
      "100000.0 0.555617717043\n",
      "1000000.0 0.551611523159\n",
      "[ 0.5804478   0.58044757  0.58044599  0.58043954  0.58043637  0.58046144\n",
      "  0.5806377   0.58096289  0.5809808   0.57896189  0.57061537  0.55935874\n",
      "  0.55539988]\n",
      "tissue:  3\n",
      "1e-06 0.538151090854\n",
      "1e-05 0.538151082852\n",
      "0.0001 0.538151270911\n",
      "0.001 0.538151096856\n",
      "0.01 0.538151611018\n",
      "0.1 0.538157466865\n",
      "1.0 0.538105936612\n",
      "10.0 0.538071999909\n",
      "100.0 0.53777048281\n",
      "1000.0 0.53634578346\n",
      "10000.0 0.531867320953\n",
      "100000.0 0.525914815533\n",
      "1000000.0 0.524472534637\n",
      "1e-06 0.538415162701\n",
      "1e-05 0.538415144748\n",
      "0.0001 0.538415246485\n",
      "0.001 0.538416898213\n",
      "0.01 0.53842402977\n",
      "0.1 0.538490930758\n",
      "1.0 0.538675692945\n",
      "10.0 0.539046747363\n",
      "100.0 0.538945501195\n",
      "1000.0 0.537081441832\n",
      "10000.0 0.529724605317\n",
      "100000.0 0.523579277724\n",
      "1000000.0 0.522245469081\n",
      "1e-06 0.536384207998\n",
      "1e-05 0.536384209994\n",
      "0.0001 0.536384315815\n",
      "0.001 0.536384022313\n",
      "0.01 0.536382918184\n",
      "0.1 0.53635053708\n",
      "1.0 0.536179822492\n",
      "10.0 0.536099045433\n",
      "100.0 0.535692213134\n",
      "1000.0 0.533143611768\n",
      "10000.0 0.526152371988\n",
      "100000.0 0.522597225015\n",
      "1000000.0 0.521670733692\n",
      "1e-06 0.53822422928\n",
      "1e-05 0.538224251275\n",
      "0.0001 0.538224753176\n",
      "0.001 0.538225409045\n",
      "0.01 0.538229192294\n",
      "0.1 0.538258250524\n",
      "1.0 0.538215752963\n",
      "10.0 0.537918340024\n",
      "100.0 0.537027902851\n",
      "1000.0 0.534317855023\n",
      "10000.0 0.529133172618\n",
      "100000.0 0.525537868588\n",
      "1000000.0 0.524297334938\n",
      "1e-06 0.531685245285\n",
      "1e-05 0.531685267294\n",
      "0.0001 0.531685215272\n",
      "0.001 0.531685559419\n",
      "0.01 0.531689441081\n",
      "0.1 0.531699671459\n",
      "1.0 0.531619195015\n",
      "10.0 0.531639405666\n",
      "100.0 0.532075246205\n",
      "1000.0 0.531826735843\n",
      "10000.0 0.526688870837\n",
      "100000.0 0.521053312818\n",
      "1000000.0 0.519991552384\n",
      "[ 0.53657199  0.53657199  0.53657216  0.5365726   0.53657544  0.53659137\n",
      "  0.53655928  0.53655511  0.53630227  0.53454309  0.52871327  0.5237365\n",
      "  0.52253552]\n",
      "tissue:  4\n",
      "1e-06 0.519970877035\n",
      "1e-05 0.519970978868\n",
      "0.0001 0.519970957202\n",
      "0.001 0.519969405867\n",
      "0.01 0.519959928861\n",
      "0.1 0.519862794966\n",
      "1.0 0.51920814705\n",
      "10.0 0.517820807834\n",
      "100.0 0.517006446149\n",
      "1000.0 0.516619520403\n",
      "10000.0 0.514955549678\n",
      "100000.0 0.510878393919\n",
      "1000000.0 0.509105881791\n",
      "1e-06 0.525098951543\n",
      "1e-05 0.52509902099\n",
      "0.0001 0.525099632992\n",
      "0.001 0.525098391627\n",
      "0.01 0.525089773689\n",
      "0.1 0.525106252158\n",
      "1.0 0.525086741894\n",
      "10.0 0.523721207907\n",
      "100.0 0.522960073242\n",
      "1000.0 0.522096779884\n",
      "10000.0 0.518669484137\n",
      "100000.0 0.51527050323\n",
      "1000000.0 0.514324960764\n",
      "1e-06 0.526315819324\n",
      "1e-05 0.526315782241\n",
      "0.0001 0.526314966396\n",
      "0.001 0.526311179481\n",
      "0.01 0.526282511485\n",
      "0.1 0.526029473125\n",
      "1.0 0.524878966393\n",
      "10.0 0.523516974843\n",
      "100.0 0.523401391035\n",
      "1000.0 0.521770079134\n",
      "10000.0 0.520187654651\n",
      "100000.0 0.51937002344\n",
      "1000000.0 0.5181140088\n",
      "1e-06 0.52316207694\n",
      "1e-05 0.523162111748\n",
      "0.0001 0.523161909427\n",
      "0.001 0.523164287241\n",
      "0.01 0.523174159626\n",
      "0.1 0.523290779076\n",
      "1.0 0.523821792862\n",
      "10.0 0.523664683145\n",
      "100.0 0.52347517817\n",
      "1000.0 0.522180966811\n",
      "10000.0 0.51898183114\n",
      "100000.0 0.517023883549\n",
      "1000000.0 0.516175041187\n",
      "1e-06 0.521622605725\n",
      "1e-05 0.521622789988\n",
      "0.0001 0.521622525516\n",
      "0.001 0.521620396728\n",
      "0.01 0.521598725145\n",
      "0.1 0.521405538709\n",
      "1.0 0.520679181906\n",
      "10.0 0.520008232123\n",
      "100.0 0.520756997565\n",
      "1000.0 0.523225977697\n",
      "10000.0 0.526416398043\n",
      "100000.0 0.524436789874\n",
      "1000000.0 0.522850357158\n",
      "[ 0.52323407  0.52323414  0.523234    0.52323273  0.52322102  0.52313897\n",
      "  0.52273497  0.52174638  0.52152002  0.52117866  0.51984218  0.51739592\n",
      "  0.51611405]\n",
      "[10.0, 10.0, 100.0, 0.10000000000000001, 1.0000000000000001e-05]\n"
     ]
    }
   ],
   "source": [
    "K = 10\n",
    "num_tissues = len(train_list)\n",
    "# beta is a T x M matrix, where T = # of tissues and M = number of features (not including intercept)\n",
    "beta = np.zeros((K, num_tissues, len(annot_cols_original) - 1))\n",
    "beta_parent = np.zeros(len(annot_cols_original) - 1)\n",
    "\n",
    "delta = np.zeros((K, num_tissues, len(annot_cols_original) - 1))\n",
    "delta_parent = np.zeros((K, len(annot_cols_original) - 1))\n",
    "lambda_set = np.array([1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4, 1e5, 1e6])\n",
    "optimal_lambdas = [1, 1, 1, 1, 1]\n",
    "# determine optimal lambdas on one simulated data set\n",
    "for j in range(num_tissues):\n",
    "    print(\"tissue: \", j)\n",
    "    train_sample = bootstrap_resample(train_list[j])\n",
    "    g = train_sample[annot_cols_original].values\n",
    "    expr_label = train_sample[\"expr_label\"].values\n",
    "    optimal_lambda = _cross_validate(g, expr_label, np.zeros(len(annot_cols_original)), np.zeros(len(annot_cols_original)), lambda_set)\n",
    "    optimal_lambdas[j] = optimal_lambda\n",
    "print(optimal_lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.0, 10.0, 100.0, 0.10000000000000001, 1.0000000000000001e-05]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tissues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 5, 118)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "0\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'computeEmpiricalVariance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-12e6655b7c40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mlambda_hp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputeEmpiricalVariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;31m# simplifying assumption - variance is the smae across all features, so we take the average of the feature variances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mlambda_hp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambda_hp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlambda_hp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'computeEmpiricalVariance' is not defined"
     ]
    }
   ],
   "source": [
    "K = 100\n",
    "num_tissues = len(train_list)\n",
    "# beta is a T x M matrix, where T = # of tissues and M = number of features (not including intercept)\n",
    "beta = np.zeros((K, num_tissues, len(annot_cols_original) - 1))\n",
    "beta_parent = np.zeros(len(annot_cols_original) - 1)\n",
    "\n",
    "delta = np.zeros((K, num_tissues, len(annot_cols_original) - 1))\n",
    "delta_parent = np.zeros((K, len(annot_cols_original) - 1))\n",
    "#optimal_lambdas = [0.1, 0.1, 10.0, 0.01, 0.01]\n",
    "lambda_set = np.array([1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4, 1e5, 1e6])\n",
    "\n",
    "# for each tissue\n",
    "for j in range(num_tissues):\n",
    "    # generate K random data sets\n",
    "    optimal_lambda = optimal_lambdas[j]\n",
    "    for i in range(K):\n",
    "        train_sample = bootstrap_resample(train_list[j])\n",
    "        g = train_sample[annot_cols_original]\n",
    "        expr_label = train_sample[\"expr_label\"]\n",
    "        #optimal_lambda = _cross_validate(g, expr_label, np.zeros(len(annot_cols_original)), np.zeros(len(annot_cols_original)), lambda_set)\n",
    "        # compute L2 regularized logistic regression and store non-intercept terms\n",
    "        beta[i][j] = lr.sgd(g.values, expr_label.values, np.zeros(len(annot_cols_original)), np.zeros(len(annot_cols_original)), optimal_lambda)[1:]\n",
    "        print(i)\n",
    "# for each dataset\n",
    "for i in range(K):\n",
    "    beta_parent = estimateBetaParent(beta[i], np.ones(num_tissues), 1, num_tissues)\n",
    "    # estimate variance between each beta child and beta parent for this trial and variance of parent\n",
    "    for j in range(num_tissues):\n",
    "        delta[i][j] = (beta[i][j] - beta_parent)\n",
    "    delta_parent[i] = beta_parent\n",
    "    \n",
    "    if i > 2:\n",
    "        lambda_hp = computeEmpiricalVariance(delta, i+1)\n",
    "        # simplifying assumption - variance is the smae across all features, so we take the average of the feature variances\n",
    "        lambda_hp = np.sum(lambda_hp, axis=1) / lambda_hp.shape[1]\n",
    "\n",
    "        lambda_hp_parent = computeEmpiricalVarianceParent(delta_parent, i+1)\n",
    "        lambda_hp_parent = np.sum(lambda_hp_parent) / lambda_hp_parent.shape[0]\n",
    "        \n",
    "        print(\"lambda inverse: \", lambda_hp)\n",
    "        print(\"lambda inverse parent: \", lambda_hp_parent)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "lambda inverse:  [ 0.04557006  0.03993116  0.02910788  0.29056672  0.28088474]\n",
      "lambda inverse parent:  0.0213921627484\n",
      "3\n",
      "lambda inverse:  [ 0.04076425  0.03561766  0.0260221   0.25422676  0.23574219]\n",
      "lambda inverse parent:  0.0187218435208\n",
      "4\n",
      "lambda inverse:  [ 0.03839195  0.03273016  0.02432593  0.2339984   0.21545299]\n",
      "lambda inverse parent:  0.0174789544172\n",
      "5\n",
      "lambda inverse:  [ 0.0386579   0.03474769  0.02528818  0.22347829  0.23241074]\n",
      "lambda inverse parent:  0.0188046055568\n",
      "6\n",
      "lambda inverse:  [ 0.03686253  0.03397639  0.02433866  0.21485336  0.22445017]\n",
      "lambda inverse parent:  0.0180047311431\n",
      "7\n",
      "lambda inverse:  [ 0.0357035   0.03301635  0.02393817  0.20128899  0.21862326]\n",
      "lambda inverse parent:  0.0175642687314\n",
      "8\n",
      "lambda inverse:  [ 0.03454782  0.03258383  0.02354295  0.20165381  0.21707376]\n",
      "lambda inverse parent:  0.017128556279\n",
      "9\n",
      "lambda inverse:  [ 0.03409343  0.03179831  0.02306275  0.19692097  0.205859  ]\n",
      "lambda inverse parent:  0.0167595641422\n",
      "10\n",
      "lambda inverse:  [ 0.03350893  0.03114687  0.02242538  0.19209722  0.20030934]\n",
      "lambda inverse parent:  0.016194741579\n",
      "11\n",
      "lambda inverse:  [ 0.03291068  0.03047977  0.02201737  0.19204642  0.19735615]\n",
      "lambda inverse parent:  0.0158536069896\n",
      "12\n",
      "lambda inverse:  [ 0.03303405  0.02965347  0.02179238  0.18759104  0.19438804]\n",
      "lambda inverse parent:  0.0156285136533\n",
      "13\n",
      "lambda inverse:  [ 0.03288436  0.02907982  0.02158174  0.18407471  0.18969433]\n",
      "lambda inverse parent:  0.0153996162459\n",
      "14\n",
      "lambda inverse:  [ 0.03263873  0.02895533  0.02147599  0.18405454  0.19316256]\n",
      "lambda inverse parent:  0.0153822483354\n",
      "15\n",
      "lambda inverse:  [ 0.03304171  0.02934708  0.02157731  0.18854975  0.18811074]\n",
      "lambda inverse parent:  0.015432911112\n",
      "16\n",
      "lambda inverse:  [ 0.03302745  0.0294048   0.02185808  0.19335595  0.18705565]\n",
      "lambda inverse parent:  0.0157288340955\n",
      "17\n",
      "lambda inverse:  [ 0.03300907  0.02980625  0.02212232  0.19171754  0.18753273]\n",
      "lambda inverse parent:  0.0160000361878\n",
      "18\n",
      "lambda inverse:  [ 0.03304089  0.02965981  0.02199933  0.19334561  0.1910993 ]\n",
      "lambda inverse parent:  0.0158768992386\n",
      "19\n",
      "lambda inverse:  [ 0.03278135  0.02936669  0.02196329  0.1943703   0.18960812]\n",
      "lambda inverse parent:  0.0157916929104\n",
      "20\n",
      "lambda inverse:  [ 0.03288845  0.02908462  0.02190922  0.19295191  0.19426335]\n",
      "lambda inverse parent:  0.0156970180263\n",
      "21\n",
      "lambda inverse:  [ 0.04456235  0.04000128  0.03290458  0.19009987  0.40921503]\n",
      "lambda inverse parent:  0.0267561091288\n",
      "22\n",
      "lambda inverse:  [ 0.04421226  0.03952915  0.0322618   0.18678182  0.39785484]\n",
      "lambda inverse parent:  0.0261302484535\n",
      "23\n",
      "lambda inverse:  [ 0.04393612  0.03918972  0.03203307  0.18658003  0.38655361]\n",
      "lambda inverse parent:  0.0259307439048\n",
      "24\n",
      "lambda inverse:  [ 0.04356751  0.03854119  0.03147017  0.18596106  0.38188202]\n",
      "lambda inverse parent:  0.0253884779889\n",
      "25\n",
      "lambda inverse:  [ 0.04317606  0.03801319  0.03111728  0.18859121  0.3743713 ]\n",
      "lambda inverse parent:  0.0250401481023\n",
      "26\n",
      "lambda inverse:  [ 0.04301093  0.03763296  0.03099864  0.18624143  0.3671078 ]\n",
      "lambda inverse parent:  0.0248716863742\n",
      "27\n",
      "lambda inverse:  [ 0.04282177  0.03759873  0.0309731   0.1860365   0.36348812]\n",
      "lambda inverse parent:  0.0248702452054\n",
      "28\n",
      "lambda inverse:  [ 0.04231617  0.03710572  0.03058952  0.18491572  0.35634093]\n",
      "lambda inverse parent:  0.0244992546143\n",
      "29\n",
      "lambda inverse:  [ 0.0418306   0.03673803  0.03016414  0.18325366  0.34803262]\n",
      "lambda inverse parent:  0.0240777603773\n",
      "30\n",
      "lambda inverse:  [ 0.04183702  0.03656075  0.02999699  0.18331793  0.34284366]\n",
      "lambda inverse parent:  0.0238949203069\n",
      "31\n",
      "lambda inverse:  [ 0.04159878  0.03623258  0.02964795  0.18200563  0.33594925]\n",
      "lambda inverse parent:  0.0235365339074\n",
      "32\n",
      "lambda inverse:  [ 0.04152303  0.03607776  0.02954421  0.18057331  0.33316834]\n",
      "lambda inverse parent:  0.0234681615376\n",
      "33\n",
      "lambda inverse:  [ 0.04129533  0.03578417  0.02935262  0.17977927  0.3297534 ]\n",
      "lambda inverse parent:  0.0232732232735\n",
      "34\n",
      "lambda inverse:  [ 0.0409739   0.03539117  0.02905793  0.18041512  0.32389117]\n",
      "lambda inverse parent:  0.0229930050521\n",
      "35\n",
      "lambda inverse:  [ 0.04068577  0.03524607  0.02891813  0.1789779   0.32013069]\n",
      "lambda inverse parent:  0.0228800854121\n",
      "36\n",
      "lambda inverse:  [ 0.04062258  0.03501729  0.02879765  0.18224625  0.3135457 ]\n",
      "lambda inverse parent:  0.0227828369165\n",
      "37\n",
      "lambda inverse:  [ 0.04031297  0.03487785  0.02865421  0.18387928  0.31315609]\n",
      "lambda inverse parent:  0.0226462154952\n",
      "38\n",
      "lambda inverse:  [ 0.04018429  0.03471689  0.02863651  0.18254698  0.31065351]\n",
      "lambda inverse parent:  0.0225922606258\n",
      "39\n",
      "lambda inverse:  [ 0.04000075  0.03464148  0.02851523  0.18325129  0.30842673]\n",
      "lambda inverse parent:  0.0224610929083\n",
      "40\n",
      "lambda inverse:  [ 0.03978183  0.03429453  0.02824674  0.18339159  0.30750825]\n",
      "lambda inverse parent:  0.0221567765849\n",
      "41\n",
      "lambda inverse:  [ 0.03955583  0.03407148  0.02802114  0.18270469  0.30489745]\n",
      "lambda inverse parent:  0.0219447570462\n",
      "42\n",
      "lambda inverse:  [ 0.03940776  0.03407566  0.02793003  0.18206835  0.29995249]\n",
      "lambda inverse parent:  0.021842778245\n",
      "43\n",
      "lambda inverse:  [ 0.03944331  0.0339438   0.02782097  0.18207368  0.29830542]\n",
      "lambda inverse parent:  0.02176002355\n",
      "44\n",
      "lambda inverse:  [ 0.03931078  0.03372361  0.02766393  0.18166056  0.29530216]\n",
      "lambda inverse parent:  0.0215929429985\n",
      "45\n",
      "lambda inverse:  [ 0.03920535  0.03361472  0.02745092  0.18085535  0.29169574]\n",
      "lambda inverse parent:  0.0213813632104\n",
      "46\n",
      "lambda inverse:  [ 0.03893145  0.03348308  0.02726222  0.17845593  0.28889969]\n",
      "lambda inverse parent:  0.0211779770776\n",
      "47\n",
      "lambda inverse:  [ 0.03854629  0.03322831  0.02701564  0.17708179  0.28481914]\n",
      "lambda inverse parent:  0.0209149670795\n",
      "48\n",
      "lambda inverse:  [ 0.03847671  0.03309529  0.02688133  0.17910905  0.28129239]\n",
      "lambda inverse parent:  0.0207844283146\n",
      "49\n",
      "lambda inverse:  [ 0.03843959  0.03301189  0.02680784  0.17879101  0.27942367]\n",
      "lambda inverse parent:  0.0207255958744\n",
      "50\n",
      "lambda inverse:  [ 0.03901391  0.03345278  0.02730999  0.178858    0.28712357]\n",
      "lambda inverse parent:  0.0212240740697\n",
      "51\n",
      "lambda inverse:  [ 0.038812    0.03327423  0.02708202  0.17936045  0.28413746]\n",
      "lambda inverse parent:  0.020999431596\n",
      "52\n",
      "lambda inverse:  [ 0.03862585  0.03316148  0.02688216  0.17828689  0.28086068]\n",
      "lambda inverse parent:  0.0208008794264\n",
      "53\n",
      "lambda inverse:  [ 0.03849088  0.03289877  0.02668965  0.17864751  0.27846229]\n",
      "lambda inverse parent:  0.020626852932\n",
      "54\n",
      "lambda inverse:  [ 0.03830499  0.03278674  0.02656553  0.1783852   0.27509322]\n",
      "lambda inverse parent:  0.0205038304634\n",
      "55\n",
      "lambda inverse:  [ 0.03811927  0.0326867   0.02649285  0.17767816  0.27363502]\n",
      "lambda inverse parent:  0.0204342858619\n",
      "56\n",
      "lambda inverse:  [ 0.03805114  0.03251546  0.02638806  0.17729795  0.27371045]\n",
      "lambda inverse parent:  0.0203377156256\n",
      "57\n",
      "lambda inverse:  [ 0.03787338  0.03244111  0.02631752  0.17656279  0.27066148]\n",
      "lambda inverse parent:  0.0202610236028\n",
      "58\n",
      "lambda inverse:  [ 0.03777332  0.03245546  0.02631074  0.17789731  0.26854154]\n",
      "lambda inverse parent:  0.0202613012568\n",
      "59\n",
      "lambda inverse:  [ 0.03767894  0.03228831  0.02618204  0.17731144  0.26555148]\n",
      "lambda inverse parent:  0.0201399850695\n",
      "60\n",
      "lambda inverse:  [ 0.03751863  0.03231515  0.02607516  0.17869071  0.26677882]\n",
      "lambda inverse parent:  0.0200354211904\n",
      "61\n",
      "lambda inverse:  [ 0.03738594  0.03217227  0.02592235  0.17808806  0.2648129 ]\n",
      "lambda inverse parent:  0.0198663769891\n",
      "62\n",
      "lambda inverse:  [ 0.03737705  0.03196449  0.02578249  0.17716223  0.26236874]\n",
      "lambda inverse parent:  0.0197274771327\n",
      "63\n",
      "lambda inverse:  [ 0.03737795  0.03198907  0.0256746   0.17795673  0.26032239]\n",
      "lambda inverse parent:  0.0196275132225\n",
      "64\n",
      "lambda inverse:  [ 0.03730704  0.03210552  0.02564991  0.17865421  0.26036558]\n",
      "lambda inverse parent:  0.01960734378\n",
      "65\n",
      "lambda inverse:  [ 0.03716038  0.03203254  0.02552624  0.17742417  0.25853198]\n",
      "lambda inverse parent:  0.0194910774677\n",
      "66\n",
      "lambda inverse:  [ 0.03710943  0.03192305  0.02540122  0.17762739  0.25624713]\n",
      "lambda inverse parent:  0.0193751710615\n",
      "67\n",
      "lambda inverse:  [ 0.03693471  0.03179779  0.02530362  0.17810123  0.25528241]\n",
      "lambda inverse parent:  0.0192690929011\n",
      "68\n",
      "lambda inverse:  [ 0.03686028  0.03174834  0.02523997  0.17831787  0.25437404]\n",
      "lambda inverse parent:  0.0191981810437\n",
      "69\n",
      "lambda inverse:  [ 0.03682512  0.03180316  0.02527029  0.17833115  0.25368578]\n",
      "lambda inverse parent:  0.0192352627545\n",
      "70\n",
      "lambda inverse:  [ 0.0368128   0.03174322  0.02520628  0.17804907  0.25258129]\n",
      "lambda inverse parent:  0.0191811971139\n",
      "71\n",
      "lambda inverse:  [ 0.03671566  0.03169423  0.02511258  0.17724342  0.2503303 ]\n",
      "lambda inverse parent:  0.0190788943254\n",
      "72\n",
      "lambda inverse:  [ 0.03663247  0.03155328  0.02504577  0.17713815  0.24822232]\n",
      "lambda inverse parent:  0.0190028800879\n",
      "73\n",
      "lambda inverse:  [ 0.03660213  0.03154428  0.02501185  0.17685301  0.24732027]\n",
      "lambda inverse parent:  0.0189845280646\n",
      "74\n",
      "lambda inverse:  [ 0.03648294  0.03144615  0.02488958  0.17572147  0.24516386]\n",
      "lambda inverse parent:  0.0188739764803\n",
      "75\n",
      "lambda inverse:  [ 0.03653341  0.03139762  0.02482974  0.17492289  0.2439079 ]\n",
      "lambda inverse parent:  0.0188030228668\n",
      "76\n",
      "lambda inverse:  [ 0.03656938  0.03151101  0.02496541  0.1750244   0.24320751]\n",
      "lambda inverse parent:  0.0189272653989\n",
      "77\n",
      "lambda inverse:  [ 0.03663011  0.0314345   0.02496054  0.17449522  0.24162979]\n",
      "lambda inverse parent:  0.0189326276737\n",
      "78\n",
      "lambda inverse:  [ 0.0366978   0.03154469  0.02507553  0.17460896  0.24231398]\n",
      "lambda inverse parent:  0.0190512951611\n",
      "79\n",
      "lambda inverse:  [ 0.0365492   0.03141876  0.02496884  0.17560222  0.24319273]\n",
      "lambda inverse parent:  0.0189289599951\n",
      "80\n",
      "lambda inverse:  [ 0.03650475  0.03142658  0.02493224  0.17473562  0.24221929]\n",
      "lambda inverse parent:  0.018906009474\n",
      "81\n",
      "lambda inverse:  [ 0.0363819   0.03134998  0.02484361  0.17469469  0.24072595]\n",
      "lambda inverse parent:  0.0188311086879\n",
      "82\n",
      "lambda inverse:  [ 0.03633944  0.03124688  0.0248103   0.17569497  0.23981734]\n",
      "lambda inverse parent:  0.0187909660492\n",
      "83\n",
      "lambda inverse:  [ 0.03753332  0.03235814  0.0259811   0.17541328  0.26705799]\n",
      "lambda inverse parent:  0.019970387221\n",
      "84\n",
      "lambda inverse:  [ 0.03745168  0.03224769  0.02588607  0.17463539  0.2652529 ]\n",
      "lambda inverse parent:  0.0198649854542\n",
      "85\n",
      "lambda inverse:  [ 0.03743007  0.03215541  0.02583437  0.17417104  0.26419944]\n",
      "lambda inverse parent:  0.0198051508794\n",
      "86\n",
      "lambda inverse:  [ 0.03739761  0.03223338  0.02585099  0.17403772  0.26300521]\n",
      "lambda inverse parent:  0.0198171975649\n",
      "87\n",
      "lambda inverse:  [ 0.03725684  0.03213855  0.02573244  0.17489866  0.2634571 ]\n",
      "lambda inverse parent:  0.0197046720054\n",
      "88\n",
      "lambda inverse:  [ 0.0371615   0.032115    0.02565073  0.17431991  0.26215808]\n",
      "lambda inverse parent:  0.0196227252978\n",
      "89\n",
      "lambda inverse:  [ 0.03715362  0.03204174  0.02562627  0.17401047  0.26011404]\n",
      "lambda inverse parent:  0.0195968433358\n",
      "90\n",
      "lambda inverse:  [ 0.03707904  0.03198443  0.02556142  0.17397121  0.25810437]\n",
      "lambda inverse parent:  0.0195352255346\n",
      "91\n",
      "lambda inverse:  [ 0.03698979  0.03191868  0.02550717  0.17319093  0.25708913]\n",
      "lambda inverse parent:  0.0194826790017\n",
      "92\n",
      "lambda inverse:  [ 0.03689151  0.03185415  0.02541078  0.17259247  0.25566832]\n",
      "lambda inverse parent:  0.019390624063\n",
      "93\n",
      "lambda inverse:  [ 0.03686243  0.03181846  0.02535831  0.17213801  0.25453931]\n",
      "lambda inverse parent:  0.0193346714734\n",
      "94\n",
      "lambda inverse:  [ 0.03685044  0.03183019  0.02539018  0.17210862  0.25506727]\n",
      "lambda inverse parent:  0.0193684063697\n",
      "95\n",
      "lambda inverse:  [ 0.03686366  0.03172008  0.02537285  0.1716294   0.25384725]\n",
      "lambda inverse parent:  0.0193423759318\n",
      "96\n",
      "lambda inverse:  [ 0.03681188  0.03159855  0.0252538   0.17106716  0.2524167 ]\n",
      "lambda inverse parent:  0.0192322757239\n",
      "97\n",
      "lambda inverse:  [ 0.0367932   0.03156841  0.02526325  0.17047088  0.25292157]\n",
      "lambda inverse parent:  0.0192385402909\n",
      "98\n",
      "lambda inverse:  [ 0.03676788  0.03152354  0.02518621  0.16961407  0.25169157]\n",
      "lambda inverse parent:  0.0191736899286\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "# for each dataset\n",
    "for i in range(K):\n",
    "    beta_parent = estimateBetaParent(beta[i], np.ones(num_tissues), 1, num_tissues)\n",
    "    # estimate variance between each beta child and beta parent for this trial and variance of parent\n",
    "    for j in range(num_tissues):\n",
    "        delta[i][j] = (beta[i][j] - beta_parent)\n",
    "    delta_parent[i] = beta_parent\n",
    "    \n",
    "    if i > 2:\n",
    "        lambda_hp = computeEmpiricalVariance(delta, i+1)\n",
    "        # simplifying assumption - variance is the smae across all features, so we take the average of the feature variances\n",
    "        lambda_hp = np.sum(lambda_hp, axis=1) / lambda_hp.shape[1]\n",
    "\n",
    "        lambda_hp_parent = computeEmpiricalVarianceParent(delta_parent, i+1)\n",
    "        lambda_hp_parent = np.sum(lambda_hp_parent) / lambda_hp_parent.shape[0]\n",
    "        \n",
    "        print(\"lambda inverse: \", lambda_hp)\n",
    "        print(\"lambda inverse parent: \", lambda_hp_parent)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>intercept</th>\n",
       "      <th>max_CpG_10kb</th>\n",
       "      <th>max_PHRED_10kb</th>\n",
       "      <th>max_verPhCons_10kb</th>\n",
       "      <th>max_cHmmTssA_10kb</th>\n",
       "      <th>max_mamPhCons_10kb</th>\n",
       "      <th>max_verPhyloP_10kb</th>\n",
       "      <th>max_GC_10kb</th>\n",
       "      <th>max_EncOCpolIIPVal_10kb</th>\n",
       "      <th>max_TFBS_10kb</th>\n",
       "      <th>...</th>\n",
       "      <th>E110_general_promoter</th>\n",
       "      <th>E110_general_enhancer</th>\n",
       "      <th>E111_general_promoter</th>\n",
       "      <th>E111_general_enhancer</th>\n",
       "      <th>E113_general_promoter</th>\n",
       "      <th>E113_general_enhancer</th>\n",
       "      <th>expr_median</th>\n",
       "      <th>expr_label</th>\n",
       "      <th>posterior</th>\n",
       "      <th>tissue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_id</th>\n",
       "      <th>gene_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">GTEX-N7MS</th>\n",
       "      <th>ENSG00000001561.6</th>\n",
       "      <td>1</td>\n",
       "      <td>0.572087</td>\n",
       "      <td>0.376902</td>\n",
       "      <td>0.578286</td>\n",
       "      <td>1.010185</td>\n",
       "      <td>0.560247</td>\n",
       "      <td>0.672983</td>\n",
       "      <td>1.015867</td>\n",
       "      <td>1.184023</td>\n",
       "      <td>0.372614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.685943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>muscle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000003056.3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.592920</td>\n",
       "      <td>0.364608</td>\n",
       "      <td>0.582093</td>\n",
       "      <td>1.026185</td>\n",
       "      <td>0.563769</td>\n",
       "      <td>0.676492</td>\n",
       "      <td>1.156892</td>\n",
       "      <td>1.184023</td>\n",
       "      <td>0.372614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.712559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>muscle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000003402.15</th>\n",
       "      <td>1</td>\n",
       "      <td>0.801254</td>\n",
       "      <td>0.388538</td>\n",
       "      <td>0.577017</td>\n",
       "      <td>1.687185</td>\n",
       "      <td>0.559807</td>\n",
       "      <td>0.668350</td>\n",
       "      <td>1.451764</td>\n",
       "      <td>1.344023</td>\n",
       "      <td>0.582698</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.218652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>muscle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000004534.10</th>\n",
       "      <td>1</td>\n",
       "      <td>0.676254</td>\n",
       "      <td>0.427440</td>\n",
       "      <td>0.602396</td>\n",
       "      <td>1.018185</td>\n",
       "      <td>0.584898</td>\n",
       "      <td>0.704711</td>\n",
       "      <td>1.323559</td>\n",
       "      <td>1.184023</td>\n",
       "      <td>0.372614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.569600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>muscle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000004779.5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.655420</td>\n",
       "      <td>0.417421</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.010185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.259456</td>\n",
       "      <td>1.184023</td>\n",
       "      <td>0.372614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.168581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>muscle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               intercept  max_CpG_10kb  max_PHRED_10kb  \\\n",
       "subject_id gene_id                                                       \n",
       "GTEX-N7MS  ENSG00000001561.6           1      0.572087        0.376902   \n",
       "           ENSG00000003056.3           1      0.592920        0.364608   \n",
       "           ENSG00000003402.15          1      0.801254        0.388538   \n",
       "           ENSG00000004534.10          1      0.676254        0.427440   \n",
       "           ENSG00000004779.5           1      0.655420        0.417421   \n",
       "\n",
       "                               max_verPhCons_10kb  max_cHmmTssA_10kb  \\\n",
       "subject_id gene_id                                                     \n",
       "GTEX-N7MS  ENSG00000001561.6             0.578286           1.010185   \n",
       "           ENSG00000003056.3             0.582093           1.026185   \n",
       "           ENSG00000003402.15            0.577017           1.687185   \n",
       "           ENSG00000004534.10            0.602396           1.018185   \n",
       "           ENSG00000004779.5             0.000000           1.010185   \n",
       "\n",
       "                               max_mamPhCons_10kb  max_verPhyloP_10kb  \\\n",
       "subject_id gene_id                                                      \n",
       "GTEX-N7MS  ENSG00000001561.6             0.560247            0.672983   \n",
       "           ENSG00000003056.3             0.563769            0.676492   \n",
       "           ENSG00000003402.15            0.559807            0.668350   \n",
       "           ENSG00000004534.10            0.584898            0.704711   \n",
       "           ENSG00000004779.5             0.000000            0.000000   \n",
       "\n",
       "                               max_GC_10kb  max_EncOCpolIIPVal_10kb  \\\n",
       "subject_id gene_id                                                    \n",
       "GTEX-N7MS  ENSG00000001561.6      1.015867                 1.184023   \n",
       "           ENSG00000003056.3      1.156892                 1.184023   \n",
       "           ENSG00000003402.15     1.451764                 1.344023   \n",
       "           ENSG00000004534.10     1.323559                 1.184023   \n",
       "           ENSG00000004779.5      1.259456                 1.184023   \n",
       "\n",
       "                               max_TFBS_10kb   ...    E110_general_promoter  \\\n",
       "subject_id gene_id                             ...                            \n",
       "GTEX-N7MS  ENSG00000001561.6        0.372614   ...                      0.0   \n",
       "           ENSG00000003056.3        0.372614   ...                      0.0   \n",
       "           ENSG00000003402.15       0.582698   ...                      1.0   \n",
       "           ENSG00000004534.10       0.372614   ...                      0.0   \n",
       "           ENSG00000004779.5        0.372614   ...                      0.0   \n",
       "\n",
       "                               E110_general_enhancer  E111_general_promoter  \\\n",
       "subject_id gene_id                                                            \n",
       "GTEX-N7MS  ENSG00000001561.6                     0.0                    0.0   \n",
       "           ENSG00000003056.3                     1.0                    0.0   \n",
       "           ENSG00000003402.15                    0.0                    1.0   \n",
       "           ENSG00000004534.10                    0.0                    0.0   \n",
       "           ENSG00000004779.5                     0.0                    0.0   \n",
       "\n",
       "                               E111_general_enhancer  E113_general_promoter  \\\n",
       "subject_id gene_id                                                            \n",
       "GTEX-N7MS  ENSG00000001561.6                     0.0                    0.0   \n",
       "           ENSG00000003056.3                     0.0                    0.0   \n",
       "           ENSG00000003402.15                    0.0                    1.0   \n",
       "           ENSG00000004534.10                    0.0                    0.0   \n",
       "           ENSG00000004779.5                     0.0                    0.0   \n",
       "\n",
       "                               E113_general_enhancer  expr_median  expr_label  \\\n",
       "subject_id gene_id                                                              \n",
       "GTEX-N7MS  ENSG00000001561.6                     0.0     0.685943         0.0   \n",
       "           ENSG00000003056.3                     1.0     0.712559         0.0   \n",
       "           ENSG00000003402.15                    0.0     1.218652         0.0   \n",
       "           ENSG00000004534.10                    0.0     0.569600         0.0   \n",
       "           ENSG00000004779.5                     0.0     0.168581         0.0   \n",
       "\n",
       "                               posterior  tissue  \n",
       "subject_id gene_id                                \n",
       "GTEX-N7MS  ENSG00000001561.6           0  muscle  \n",
       "           ENSG00000003056.3           0  muscle  \n",
       "           ENSG00000003402.15          0  muscle  \n",
       "           ENSG00000004534.10          0  muscle  \n",
       "           ENSG00000004779.5           0  muscle  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lambda_inverse = np.array([0.65934762, 0.449465, 0.19330769, 1.77863469, 1.32106232])\n",
    "lambda_parent_inverse = 0.230784442882"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 27.19765059,  31.72232083,  39.70426765,   5.89573747,   3.97311684])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_hp_children = 1.0 / lambda_hp\n",
    "lambda_hp_children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.154801904189519"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_parent = 1.0 / lambda_hp_parent\n",
    "lambda_parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeEmpiricalVariance(delta, K):\n",
    "    lambda_hp = np.zeros((num_tissues, len(annot_cols_original) - 1))\n",
    "    for t in range(num_tissues):\n",
    "        for j in range(len(annot_cols_original) - 1):\n",
    "            lambda_hp[t][j] = np.sum(delta[:,t,j]**2) / (K-1)\n",
    "    return lambda_hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeEmpiricalVarianceParent(delta, K):\n",
    "    lambda_hp = np.zeros(len(annot_cols_original) - 1)\n",
    "    for j in range(len(annot_cols_original) - 1):\n",
    "        lambda_hp[j] = np.sum(delta[:,j]**2) / (K-1)\n",
    "    return lambda_hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
